openapi: 3.0.0
info:
  contact:
    name: OpenAI Support
    url: https://help.openai.com/
  description: The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference
    for more details.
  license:
    name: MIT
    url: https://github.com/openai/openai-openapi/blob/master/LICENSE
  termsOfService: https://openai.com/policies/terms-of-use
  title: OpenAI API
  version: 2.0.0
servers:
- url: https://api.openai.com/v1
security:
- ApiKeyAuth: []
tags:
- description: Learn how to turn audio into text or text into audio.
  name: Audio
- description: "Given a list of messages comprising a conversation, the model will\
    \ return a response."
  name: Chat
- description: "Given a prompt, the model will return one or more predicted completions,\
    \ and can also return the probabilities of alternative tokens at each position."
  name: Completions
- description: Get a vector representation of a given input that can be easily consumed
    by machine learning models and algorithms.
  name: Embeddings
- description: Manage fine-tuning jobs to tailor a model to your specific training
    data.
  name: Fine-tuning
- description: Create large batches of API requests to run asynchronously.
  name: Batch
- description: Files are used to upload documents that can be used with features like
    Assistants and Fine-tuning.
  name: Files
- description: "Given a prompt and/or an input image, the model will generate a new\
    \ image."
  name: Images
- description: List and describe the various models available in the API.
  name: Models
- description: "Given a input text, outputs if the model classifies it as potentially\
    \ harmful."
  name: Moderations
paths:
  /chat/completions:
    post:
      operationId: createChatCompletion
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateChatCompletionRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateChatCompletionResponse"
          description: OK
      summary: Creates a model response for the given chat conversation.
      tags:
      - Chat
      x-oaiMeta:
        name: Create chat completion
        group: chat
        returns: |
          Returns a [chat completion](/docs/api-reference/chat/object) object, or a streamed sequence of [chat completion chunk](/docs/api-reference/chat/streaming) objects if the request is streamed.
        path: create
        examples:
        - title: Default
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_model_id",
                  "messages": [
                    {
                      "role": "system",
                      "content": "You are a helpful assistant."
                    },
                    {
                      "role": "user",
                      "content": "Hello!"
                    }
                  ]
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              completion = client.chat.completions.create(
                model="VAR_model_id",
                messages=[
                  {"role": "system", "content": "You are a helpful assistant."},
                  {"role": "user", "content": "Hello!"}
                ]
              )

              print(completion.choices[0].message)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.chat.completions.create({
                  messages: [{ role: "system", content: "You are a helpful assistant." }],
                  model: "VAR_model_id",
                });

                console.log(completion.choices[0]);
              }

              main();
          response: |
            {
              "id": "chatcmpl-123",
              "object": "chat.completion",
              "created": 1677652288,
              "model": "gpt-3.5-turbo-0125",
              "system_fingerprint": "fp_44709d6fcb",
              "choices": [{
                "index": 0,
                "message": {
                  "role": "assistant",
                  "content": "\n\nHello there, how may I assist you today?",
                },
                "logprobs": null,
                "finish_reason": "stop"
              }],
              "usage": {
                "prompt_tokens": 9,
                "completion_tokens": 12,
                "total_tokens": 21
              }
            }
        - title: Image input
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4-turbo",
                  "messages": [
                    {
                      "role": "user",
                      "content": [
                        {
                          "type": "text",
                          "text": "What'\''s in this image?"
                        },
                        {
                          "type": "image_url",
                          "image_url": {
                            "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
                          }
                        }
                      ]
                    }
                  ],
                  "max_tokens": 300
                }'
            python: |
              from openai import OpenAI

              client = OpenAI()

              response = client.chat.completions.create(
                  model="gpt-4-turbo",
                  messages=[
                      {
                          "role": "user",
                          "content": [
                              {"type": "text", "text": "What's in this image?"},
                              {
                                  "type": "image_url",
                                  "image_url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
                              },
                          ],
                      }
                  ],
                  max_tokens=300,
              )

              print(response.choices[0])
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const response = await openai.chat.completions.create({
                  model: "gpt-4-turbo",
                  messages: [
                    {
                      role: "user",
                      content: [
                        { type: "text", text: "What's in this image?" },
                        {
                          type: "image_url",
                          image_url:
                            "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
                        },
                      ],
                    },
                  ],
                });
                console.log(response.choices[0]);
              }
              main();
          response: |
            {
              "id": "chatcmpl-123",
              "object": "chat.completion",
              "created": 1677652288,
              "model": "gpt-3.5-turbo-0125",
              "system_fingerprint": "fp_44709d6fcb",
              "choices": [{
                "index": 0,
                "message": {
                  "role": "assistant",
                  "content": "\n\nThis image shows a wooden boardwalk extending through a lush green marshland.",
                },
                "logprobs": null,
                "finish_reason": "stop"
              }],
              "usage": {
                "prompt_tokens": 9,
                "completion_tokens": 12,
                "total_tokens": 21
              }
            }
        - title: Streaming
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_model_id",
                  "messages": [
                    {
                      "role": "system",
                      "content": "You are a helpful assistant."
                    },
                    {
                      "role": "user",
                      "content": "Hello!"
                    }
                  ],
                  "stream": true
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              completion = client.chat.completions.create(
                model="VAR_model_id",
                messages=[
                  {"role": "system", "content": "You are a helpful assistant."},
                  {"role": "user", "content": "Hello!"}
                ],
                stream=True
              )

              for chunk in completion:
                print(chunk.choices[0].delta)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.chat.completions.create({
                  model: "VAR_model_id",
                  messages: [
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "Hello!"}
                  ],
                  stream: true,
                });

                for await (const chunk of completion) {
                  console.log(chunk.choices[0].delta.content);
                }
              }

              main();
          response: |
            {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0125", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

            {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0125", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}

            ....

            {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0125", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
        - title: Functions
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
              -H "Content-Type: application/json" \
              -H "Authorization: Bearer $OPENAI_API_KEY" \
              -d '{
                "model": "gpt-4-turbo",
                "messages": [
                  {
                    "role": "user",
                    "content": "What'\''s the weather like in Boston today?"
                  }
                ],
                "tools": [
                  {
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {
                            "type": "string",
                            "description": "The city and state, e.g. San Francisco, CA"
                          },
                          "unit": {
                            "type": "string",
                            "enum": ["celsius", "fahrenheit"]
                          }
                        },
                        "required": ["location"]
                      }
                    }
                  }
                ],
                "tool_choice": "auto"
              }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              tools = [
                {
                  "type": "function",
                  "function": {
                    "name": "get_current_weather",
                    "description": "Get the current weather in a given location",
                    "parameters": {
                      "type": "object",
                      "properties": {
                        "location": {
                          "type": "string",
                          "description": "The city and state, e.g. San Francisco, CA",
                        },
                        "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                      },
                      "required": ["location"],
                    },
                  }
                }
              ]
              messages = [{"role": "user", "content": "What's the weather like in Boston today?"}]
              completion = client.chat.completions.create(
                model="VAR_model_id",
                messages=messages,
                tools=tools,
                tool_choice="auto"
              )

              print(completion)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const messages = [{"role": "user", "content": "What's the weather like in Boston today?"}];
                const tools = [
                    {
                      "type": "function",
                      "function": {
                        "name": "get_current_weather",
                        "description": "Get the current weather in a given location",
                        "parameters": {
                          "type": "object",
                          "properties": {
                            "location": {
                              "type": "string",
                              "description": "The city and state, e.g. San Francisco, CA",
                            },
                            "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                          },
                          "required": ["location"],
                        },
                      }
                    }
                ];

                const response = await openai.chat.completions.create({
                  model: "gpt-4-turbo",
                  messages: messages,
                  tools: tools,
                  tool_choice: "auto",
                });

                console.log(response);
              }

              main();
          response: |
            {
              "id": "chatcmpl-abc123",
              "object": "chat.completion",
              "created": 1699896916,
              "model": "gpt-3.5-turbo-0125",
              "choices": [
                {
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": null,
                    "tool_calls": [
                      {
                        "id": "call_abc123",
                        "type": "function",
                        "function": {
                          "name": "get_current_weather",
                          "arguments": "{\n\"location\": \"Boston, MA\"\n}"
                        }
                      }
                    ]
                  },
                  "logprobs": null,
                  "finish_reason": "tool_calls"
                }
              ],
              "usage": {
                "prompt_tokens": 82,
                "completion_tokens": 17,
                "total_tokens": 99
              }
            }
        - title: Logprobs
          request:
            curl: |
              curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "VAR_model_id",
                  "messages": [
                    {
                      "role": "user",
                      "content": "Hello!"
                    }
                  ],
                  "logprobs": true,
                  "top_logprobs": 2
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              completion = client.chat.completions.create(
                model="VAR_model_id",
                messages=[
                  {"role": "user", "content": "Hello!"}
                ],
                logprobs=True,
                top_logprobs=2
              )

              print(completion.choices[0].message)
              print(completion.choices[0].logprobs)
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const completion = await openai.chat.completions.create({
                  messages: [{ role: "user", content: "Hello!" }],
                  model: "VAR_model_id",
                  logprobs: true,
                  top_logprobs: 2,
                });

                console.log(completion.choices[0]);
              }

              main();
          response: |
            {
              "id": "chatcmpl-123",
              "object": "chat.completion",
              "created": 1702685778,
              "model": "gpt-3.5-turbo-0125",
              "choices": [
                {
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": "Hello! How can I assist you today?"
                  },
                  "logprobs": {
                    "content": [
                      {
                        "token": "Hello",
                        "logprob": -0.31725305,
                        "bytes": [72, 101, 108, 108, 111],
                        "top_logprobs": [
                          {
                            "token": "Hello",
                            "logprob": -0.31725305,
                            "bytes": [72, 101, 108, 108, 111]
                          },
                          {
                            "token": "Hi",
                            "logprob": -1.3190403,
                            "bytes": [72, 105]
                          }
                        ]
                      },
                      {
                        "token": "!",
                        "logprob": -0.02380986,
                        "bytes": [
                          33
                        ],
                        "top_logprobs": [
                          {
                            "token": "!",
                            "logprob": -0.02380986,
                            "bytes": [33]
                          },
                          {
                            "token": " there",
                            "logprob": -3.787621,
                            "bytes": [32, 116, 104, 101, 114, 101]
                          }
                        ]
                      },
                      {
                        "token": " How",
                        "logprob": -0.000054669687,
                        "bytes": [32, 72, 111, 119],
                        "top_logprobs": [
                          {
                            "token": " How",
                            "logprob": -0.000054669687,
                            "bytes": [32, 72, 111, 119]
                          },
                          {
                            "token": "<|end|>",
                            "logprob": -10.953937,
                            "bytes": null
                          }
                        ]
                      },
                      {
                        "token": " can",
                        "logprob": -0.015801601,
                        "bytes": [32, 99, 97, 110],
                        "top_logprobs": [
                          {
                            "token": " can",
                            "logprob": -0.015801601,
                            "bytes": [32, 99, 97, 110]
                          },
                          {
                            "token": " may",
                            "logprob": -4.161023,
                            "bytes": [32, 109, 97, 121]
                          }
                        ]
                      },
                      {
                        "token": " I",
                        "logprob": -3.7697225e-6,
                        "bytes": [
                          32,
                          73
                        ],
                        "top_logprobs": [
                          {
                            "token": " I",
                            "logprob": -3.7697225e-6,
                            "bytes": [32, 73]
                          },
                          {
                            "token": " assist",
                            "logprob": -13.596657,
                            "bytes": [32, 97, 115, 115, 105, 115, 116]
                          }
                        ]
                      },
                      {
                        "token": " assist",
                        "logprob": -0.04571125,
                        "bytes": [32, 97, 115, 115, 105, 115, 116],
                        "top_logprobs": [
                          {
                            "token": " assist",
                            "logprob": -0.04571125,
                            "bytes": [32, 97, 115, 115, 105, 115, 116]
                          },
                          {
                            "token": " help",
                            "logprob": -3.1089056,
                            "bytes": [32, 104, 101, 108, 112]
                          }
                        ]
                      },
                      {
                        "token": " you",
                        "logprob": -5.4385737e-6,
                        "bytes": [32, 121, 111, 117],
                        "top_logprobs": [
                          {
                            "token": " you",
                            "logprob": -5.4385737e-6,
                            "bytes": [32, 121, 111, 117]
                          },
                          {
                            "token": " today",
                            "logprob": -12.807695,
                            "bytes": [32, 116, 111, 100, 97, 121]
                          }
                        ]
                      },
                      {
                        "token": " today",
                        "logprob": -0.0040071653,
                        "bytes": [32, 116, 111, 100, 97, 121],
                        "top_logprobs": [
                          {
                            "token": " today",
                            "logprob": -0.0040071653,
                            "bytes": [32, 116, 111, 100, 97, 121]
                          },
                          {
                            "token": "?",
                            "logprob": -5.5247097,
                            "bytes": [63]
                          }
                        ]
                      },
                      {
                        "token": "?",
                        "logprob": -0.0008108172,
                        "bytes": [63],
                        "top_logprobs": [
                          {
                            "token": "?",
                            "logprob": -0.0008108172,
                            "bytes": [63]
                          },
                          {
                            "token": "?\n",
                            "logprob": -7.184561,
                            "bytes": [63, 10]
                          }
                        ]
                      }
                    ]
                  },
                  "finish_reason": "stop"
                }
              ],
              "usage": {
                "prompt_tokens": 9,
                "completion_tokens": 9,
                "total_tokens": 18
              },
              "system_fingerprint": null
            }
      x-content-type: application/json
      x-accepts:
      - application/json
  /embeddings:
    post:
      operationId: createEmbedding
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateEmbeddingRequest"
        required: true
      responses:
        "200":
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateEmbeddingResponse"
          description: OK
      summary: Creates an embedding vector representing the input text.
      tags:
      - Embeddings
      x-oaiMeta:
        name: Create embeddings
        group: embeddings
        returns: "A list of [embedding](/docs/api-reference/embeddings/object) objects."
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/embeddings \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                  "input": "The food was delicious and the waiter...",
                  "model": "text-embedding-ada-002",
                  "encoding_format": "float"
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.embeddings.create(
                model="text-embedding-ada-002",
                input="The food was delicious and the waiter...",
                encoding_format="float"
              )
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const embedding = await openai.embeddings.create({
                  model: "text-embedding-ada-002",
                  input: "The quick brown fox jumped over the lazy dog",
                  encoding_format: "float",
                });

                console.log(embedding);
              }

              main();
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "embedding",
                  "embedding": [
                    0.0023064255,
                    -0.009327292,
                    .... (1536 floats total for ada-002)
                    -0.0028842222,
                  ],
                  "index": 0
                }
              ],
              "model": "text-embedding-ada-002",
              "usage": {
                "prompt_tokens": 8,
                "total_tokens": 8
              }
            }
      x-content-type: application/json
      x-accepts:
      - application/json
components:
  schemas:
    Error:
      properties:
        code:
          nullable: true
          type: string
        message:
          nullable: false
          type: string
        param:
          nullable: true
          type: string
        type:
          nullable: false
          type: string
      required:
      - code
      - message
      - param
      - type
      type: object
    ErrorResponse:
      properties:
        error:
          $ref: "#/components/schemas/Error"
      required:
      - error
      type: object
    CreateCompletionRequest:
      properties:
        model:
          $ref: "#/components/schemas/CreateCompletionRequest_model"
        prompt:
          $ref: "#/components/schemas/CreateCompletionRequest_prompt"
        best_of:
          default: 1
          description: |
            Generates `best_of` completions server-side and returns the "best" (the one with the highest log probability per token). Results cannot be streamed.

            When used with `n`, `best_of` controls the number of candidate completions and `n` specifies how many to return â€“ `best_of` must be greater than `n`.

            **Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
          maximum: 20
          minimum: 0
          nullable: true
          type: integer
        echo:
          default: false
          description: |
            Echo back the prompt in addition to the completion
          nullable: true
          type: boolean
        frequency_penalty:
          default: 0
          description: |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

            [See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)
          maximum: 2
          minimum: -2
          nullable: true
          type: number
        logit_bias:
          additionalProperties:
            type: integer
          description: |
            Modify the likelihood of specified tokens appearing in the completion.

            Accepts a JSON object that maps tokens (specified by their token ID in the GPT tokenizer) to an associated bias value from -100 to 100. You can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to token IDs. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.

            As an example, you can pass `{"50256": -100}` to prevent the <|endoftext|> token from being generated.
          nullable: true
          type: object
          x-oaiTypeLabel: map
        logprobs:
          description: |
            Include the log probabilities on the `logprobs` most likely output tokens, as well the chosen tokens. For example, if `logprobs` is 5, the API will return a list of the 5 most likely tokens. The API will always return the `logprob` of the sampled token, so there may be up to `logprobs+1` elements in the response.

            The maximum value for `logprobs` is 5.
          maximum: 5
          minimum: 0
          nullable: true
          type: integer
        max_tokens:
          default: 16
          description: |
            The maximum number of [tokens](/tokenizer) that can be generated in the completion.

            The token count of your prompt plus `max_tokens` cannot exceed the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.
          example: 16
          minimum: 0
          nullable: true
          type: integer
        "n":
          default: 1
          description: |
            How many completions to generate for each prompt.

            **Note:** Because this parameter generates many completions, it can quickly consume your token quota. Use carefully and ensure that you have reasonable settings for `max_tokens` and `stop`.
          example: 1
          maximum: 128
          minimum: 1
          nullable: true
          type: integer
        presence_penalty:
          default: 0
          description: |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

            [See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)
          maximum: 2
          minimum: -2
          nullable: true
          type: number
        seed:
          description: |
            If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.

            Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.
          maximum: 9223372036854776000
          minimum: -9223372036854776000
          nullable: true
          type: integer
        stop:
          $ref: "#/components/schemas/CreateCompletionRequest_stop"
        stream:
          default: false
          description: |
            Whether to stream back partial progress. If set, tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).
          nullable: true
          type: boolean
        stream_options:
          $ref: "#/components/schemas/ChatCompletionStreamOptions"
        suffix:
          description: |
            The suffix that comes after a completion of inserted text.

            This parameter is only supported for `gpt-3.5-turbo-instruct`.
          example: test.
          nullable: true
          type: string
        temperature:
          default: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

            We generally recommend altering this or `top_p` but not both.
          example: 1
          maximum: 2
          minimum: 0
          nullable: true
          type: number
        top_p:
          default: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or `temperature` but not both.
          example: 1
          maximum: 1
          minimum: 0
          nullable: true
          type: number
        user:
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
          example: user-1234
          type: string
      required:
      - model
      - prompt
      type: object
    CreateCompletionResponse:
      description: |
        Represents a completion response from the API. Note: both the streamed and non-streamed response objects share the same shape (unlike the chat endpoint).
      properties:
        id:
          description: A unique identifier for the completion.
          type: string
        choices:
          description: The list of completion choices the model generated for the
            input prompt.
          items:
            $ref: "#/components/schemas/CreateCompletionResponse_choices_inner"
          type: array
        created:
          description: The Unix timestamp (in seconds) of when the completion was
            created.
          type: integer
        model:
          description: The model used for completion.
          type: string
        system_fingerprint:
          description: |
            This fingerprint represents the backend configuration that the model runs with.

            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
          type: string
        object:
          description: "The object type, which is always \"text_completion\""
          enum:
          - text_completion
          type: string
        usage:
          $ref: "#/components/schemas/CompletionUsage"
      required:
      - choices
      - created
      - id
      - model
      - object
      type: object
      x-oaiMeta:
        name: The completion object
        legacy: true
        example: |
          {
            "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
            "object": "text_completion",
            "created": 1589478378,
            "model": "gpt-4-turbo",
            "choices": [
              {
                "text": "\n\nThis is indeed a test",
                "index": 0,
                "logprobs": null,
                "finish_reason": "length"
              }
            ],
            "usage": {
              "prompt_tokens": 5,
              "completion_tokens": 7,
              "total_tokens": 12
            }
          }
    ChatCompletionRequestMessageContentPart:
      oneOf:
      - $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartText"
      - $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartImage"
      x-oaiExpandable: true
    ChatCompletionRequestMessageContentPartImage:
      properties:
        type:
          description: The type of the content part.
          enum:
          - image_url
          type: string
        image_url:
          $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartImage_image_url"
      required:
      - image_url
      - type
      title: Image content part
      type: object
    ChatCompletionRequestMessageContentPartText:
      properties:
        type:
          description: The type of the content part.
          enum:
          - text
          type: string
        text:
          description: The text content.
          type: string
      required:
      - text
      - type
      title: Text content part
      type: object
    ChatCompletionRequestMessage:
      oneOf:
      - $ref: "#/components/schemas/ChatCompletionRequestSystemMessage"
      - $ref: "#/components/schemas/ChatCompletionRequestUserMessage"
      - $ref: "#/components/schemas/ChatCompletionRequestAssistantMessage"
      - $ref: "#/components/schemas/ChatCompletionRequestToolMessage"
      - $ref: "#/components/schemas/ChatCompletionRequestFunctionMessage"
      x-oaiExpandable: true
    ChatCompletionRequestSystemMessage:
      example:
        role: system
        name: name
        content: content
      properties:
        content:
          description: The contents of the system message.
          type: string
        role:
          description: "The role of the messages author, in this case `system`."
          enum:
          - system
          type: string
        name:
          description: An optional name for the participant. Provides the model information
            to differentiate between participants of the same role.
          type: string
      required:
      - content
      - role
      title: System message
      type: object
    ChatCompletionRequestUserMessage:
      properties:
        content:
          $ref: "#/components/schemas/ChatCompletionRequestUserMessage_content"
        role:
          description: "The role of the messages author, in this case `user`."
          enum:
          - user
          type: string
        name:
          description: An optional name for the participant. Provides the model information
            to differentiate between participants of the same role.
          type: string
      required:
      - content
      - role
      title: User message
      type: object
    ChatCompletionRequestAssistantMessage:
      properties:
        content:
          description: |
            The contents of the assistant message. Required unless `tool_calls` or `function_call` is specified.
          nullable: true
          type: string
        role:
          description: "The role of the messages author, in this case `assistant`."
          enum:
          - assistant
          type: string
        name:
          description: An optional name for the participant. Provides the model information
            to differentiate between participants of the same role.
          type: string
        tool_calls:
          description: "The tool calls generated by the model, such as function calls."
          items:
            $ref: "#/components/schemas/ChatCompletionMessageToolCall"
          type: array
        function_call:
          $ref: "#/components/schemas/ChatCompletionRequestAssistantMessage_function_call"
      required:
      - role
      title: Assistant message
      type: object
    ChatCompletionRequestToolMessage:
      properties:
        role:
          description: "The role of the messages author, in this case `tool`."
          enum:
          - tool
          type: string
        content:
          description: The contents of the tool message.
          type: string
        tool_call_id:
          description: Tool call that this message is responding to.
          type: string
      required:
      - content
      - role
      - tool_call_id
      title: Tool message
      type: object
    ChatCompletionRequestFunctionMessage:
      deprecated: true
      properties:
        role:
          description: "The role of the messages author, in this case `function`."
          enum:
          - function
          type: string
        content:
          description: The contents of the function message.
          nullable: true
          type: string
        name:
          description: The name of the function to call.
          type: string
      required:
      - content
      - name
      - role
      title: Function message
      type: object
    FunctionParameters:
      additionalProperties: true
      description: "The parameters the functions accepts, described as a JSON Schema\
        \ object. See the [guide](/docs/guides/function-calling) for examples, and\
        \ the [JSON Schema reference](https://json-schema.org/understanding-json-schema/)\
        \ for documentation about the format. \n\nOmitting `parameters` defines a\
        \ function with an empty parameter list."
      type: object
    ChatCompletionFunctions:
      deprecated: true
      example:
        name: name
        description: description
        parameters:
          key: ""
      properties:
        description:
          description: "A description of what the function does, used by the model\
            \ to choose when and how to call the function."
          type: string
        name:
          description: "The name of the function to be called. Must be a-z, A-Z, 0-9,\
            \ or contain underscores and dashes, with a maximum length of 64."
          type: string
        parameters:
          additionalProperties: true
          description: "The parameters the functions accepts, described as a JSON\
            \ Schema object. See the [guide](/docs/guides/function-calling) for examples,\
            \ and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/)\
            \ for documentation about the format. \n\nOmitting `parameters` defines\
            \ a function with an empty parameter list."
          type: object
      required:
      - name
      type: object
    ChatCompletionFunctionCallOption:
      description: |
        Specifying a particular function via `{"name": "my_function"}` forces the model to call that function.
      properties:
        name:
          description: The name of the function to call.
          type: string
      required:
      - name
      type: object
    ChatCompletionTool:
      example:
        function:
          name: name
          description: description
          parameters:
            key: ""
        type: function
      properties:
        type:
          description: "The type of the tool. Currently, only `function` is supported."
          enum:
          - function
          type: string
        function:
          $ref: "#/components/schemas/FunctionObject"
      required:
      - function
      - type
      type: object
    FunctionObject:
      example:
        name: name
        description: description
        parameters:
          key: ""
      properties:
        description:
          description: "A description of what the function does, used by the model\
            \ to choose when and how to call the function."
          type: string
        name:
          description: "The name of the function to be called. Must be a-z, A-Z, 0-9,\
            \ or contain underscores and dashes, with a maximum length of 64."
          type: string
        parameters:
          additionalProperties: true
          description: "The parameters the functions accepts, described as a JSON\
            \ Schema object. See the [guide](/docs/guides/function-calling) for examples,\
            \ and the [JSON Schema reference](https://json-schema.org/understanding-json-schema/)\
            \ for documentation about the format. \n\nOmitting `parameters` defines\
            \ a function with an empty parameter list."
          type: object
      required:
      - name
      type: object
    ChatCompletionToolChoiceOption:
      description: |
        Controls which (if any) tool is called by the model.
        `none` means the model will not call any tool and instead generates a message.
        `auto` means the model can pick between generating a message or calling one or more tools.
        `required` means the model must call one or more tools.
        Specifying a particular tool via `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.

        `none` is the default when no tools are present. `auto` is the default if tools are present.
      oneOf:
      - description: |
          `none` means the model will not call any tool and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools.
        enum:
        - none
        - auto
        - required
        type: string
      - $ref: "#/components/schemas/ChatCompletionNamedToolChoice"
      x-oaiExpandable: true
    ChatCompletionNamedToolChoice:
      description: Specifies a tool the model should use. Use to force the model to
        call a specific function.
      properties:
        type:
          description: "The type of the tool. Currently, only `function` is supported."
          enum:
          - function
          type: string
        function:
          $ref: "#/components/schemas/ChatCompletionNamedToolChoice_function"
      required:
      - function
      - type
      type: object
    ChatCompletionMessageToolCalls:
      description: "The tool calls generated by the model, such as function calls."
      items:
        $ref: "#/components/schemas/ChatCompletionMessageToolCall"
      type: array
    ChatCompletionMessageToolCall:
      example:
        function:
          name: name
          arguments: arguments
        id: id
        type: function
      properties:
        id:
          description: The ID of the tool call.
          type: string
        type:
          description: "The type of the tool. Currently, only `function` is supported."
          enum:
          - function
          type: string
        function:
          $ref: "#/components/schemas/ChatCompletionMessageToolCall_function"
      required:
      - function
      - id
      - type
      type: object
    ChatCompletionMessageToolCallChunk:
      properties:
        index:
          type: integer
        id:
          description: The ID of the tool call.
          type: string
        type:
          description: "The type of the tool. Currently, only `function` is supported."
          enum:
          - function
          type: string
        function:
          $ref: "#/components/schemas/ChatCompletionMessageToolCallChunk_function"
      required:
      - index
      type: object
    ChatCompletionRole:
      description: The role of the author of a message
      enum:
      - system
      - user
      - assistant
      - tool
      - function
      type: string
    ChatCompletionStreamOptions:
      description: |
        Options for streaming response. Only set this when you set `stream: true`.
      example:
        include_usage: true
      nullable: true
      properties:
        include_usage:
          description: |
            If set, an additional chunk will be streamed before the `data: [DONE]` message. The `usage` field on this chunk shows the token usage statistics for the entire request, and the `choices` field will always be an empty array. All other chunks will also include a `usage` field, but with a null value.
          type: boolean
      type: object
    ChatCompletionResponseMessage:
      description: A chat completion message generated by the model.
      example:
        role: assistant
        function_call:
          name: name
          arguments: arguments
        tool_calls:
        - function:
            name: name
            arguments: arguments
          id: id
          type: function
        - function:
            name: name
            arguments: arguments
          id: id
          type: function
        content: content
      properties:
        content:
          description: The contents of the message.
          nullable: true
          type: string
        tool_calls:
          description: "The tool calls generated by the model, such as function calls."
          items:
            $ref: "#/components/schemas/ChatCompletionMessageToolCall"
          type: array
        role:
          description: The role of the author of this message.
          enum:
          - assistant
          type: string
        function_call:
          $ref: "#/components/schemas/ChatCompletionResponseMessage_function_call"
      required:
      - content
      - role
      type: object
    ChatCompletionStreamResponseDelta:
      description: A chat completion delta generated by streamed model responses.
      properties:
        content:
          description: The contents of the chunk message.
          nullable: true
          type: string
        function_call:
          $ref: "#/components/schemas/ChatCompletionStreamResponseDelta_function_call"
        tool_calls:
          items:
            $ref: "#/components/schemas/ChatCompletionMessageToolCallChunk"
          type: array
        role:
          description: The role of the author of this message.
          enum:
          - system
          - user
          - assistant
          - tool
          type: string
      type: object
    CreateChatCompletionRequest:
      example:
        top_logprobs: 2
        logit_bias:
          key: 6
        seed: -2147483648
        functions:
        - name: name
          description: description
          parameters:
            key: ""
        - name: name
          description: description
          parameters:
            key: ""
        - name: name
          description: description
          parameters:
            key: ""
        - name: name
          description: description
          parameters:
            key: ""
        - name: name
          description: description
          parameters:
            key: ""
        max_tokens: 5
        function_call: none
        presence_penalty: 0.25495066265333133
        tools:
        - function:
            name: name
            description: description
            parameters:
              key: ""
          type: function
        - function:
            name: name
            description: description
            parameters:
              key: ""
          type: function
        "n": 1
        logprobs: false
        top_p: 1
        frequency_penalty: -1.6796687238155954
        response_format:
          type: json_object
        stop: CreateChatCompletionRequest_stop
        stream: false
        temperature: 1
        messages:
        - role: system
          name: name
          content: content
        - role: system
          name: name
          content: content
        tool_choice: none
        model: gpt-4-turbo
        stream_options:
          include_usage: true
        user: user-1234
      properties:
        messages:
          description: "A list of messages comprising the conversation so far. [Example\
            \ Python code](https://cookbook.openai.com/examples/how_to_format_inputs_to_chatgpt_models)."
          items:
            $ref: "#/components/schemas/ChatCompletionRequestMessage"
          minItems: 1
          type: array
        model:
          $ref: "#/components/schemas/CreateChatCompletionRequest_model"
        frequency_penalty:
          default: 0
          description: |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.

            [See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)
          maximum: 2
          minimum: -2
          nullable: true
          type: number
        logit_bias:
          additionalProperties:
            type: integer
          description: |
            Modify the likelihood of specified tokens appearing in the completion.

            Accepts a JSON object that maps tokens (specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. Mathematically, the bias is added to the logits generated by the model prior to sampling. The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection; values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
          nullable: true
          type: object
          x-oaiTypeLabel: map
        logprobs:
          default: false
          description: "Whether to return log probabilities of the output tokens or\
            \ not. If true, returns the log probabilities of each output token returned\
            \ in the `content` of `message`."
          nullable: true
          type: boolean
        top_logprobs:
          description: "An integer between 0 and 20 specifying the number of most\
            \ likely tokens to return at each token position, each with an associated\
            \ log probability. `logprobs` must be set to `true` if this parameter\
            \ is used."
          maximum: 20
          minimum: 0
          nullable: true
          type: integer
        max_tokens:
          description: |
            The maximum number of [tokens](/tokenizer) that can be generated in the chat completion.

            The total length of input tokens and generated tokens is limited by the model's context length. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.
          nullable: true
          type: integer
        "n":
          default: 1
          description: How many chat completion choices to generate for each input
            message. Note that you will be charged based on the number of generated
            tokens across all of the choices. Keep `n` as `1` to minimize costs.
          example: 1
          maximum: 128
          minimum: 1
          nullable: true
          type: integer
        presence_penalty:
          default: 0
          description: |
            Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.

            [See more information about frequency and presence penalties.](/docs/guides/text-generation/parameter-details)
          maximum: 2
          minimum: -2
          nullable: true
          type: number
        response_format:
          $ref: "#/components/schemas/CreateChatCompletionRequest_response_format"
        seed:
          description: |
            This feature is in Beta.
            If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same `seed` and parameters should return the same result.
            Determinism is not guaranteed, and you should refer to the `system_fingerprint` response parameter to monitor changes in the backend.
          maximum: 9223372036854776000
          minimum: -9223372036854776000
          nullable: true
          type: integer
          x-oaiMeta:
            beta: true
        stop:
          $ref: "#/components/schemas/CreateChatCompletionRequest_stop"
        stream:
          default: false
          description: |
            If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as data-only [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format) as they become available, with the stream terminated by a `data: [DONE]` message. [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).
          nullable: true
          type: boolean
        stream_options:
          $ref: "#/components/schemas/ChatCompletionStreamOptions"
        temperature:
          default: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

            We generally recommend altering this or `top_p` but not both.
          example: 1
          maximum: 2
          minimum: 0
          nullable: true
          type: number
        top_p:
          default: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or `temperature` but not both.
          example: 1
          maximum: 1
          minimum: 0
          nullable: true
          type: number
        tools:
          description: |
            A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for. A max of 128 functions are supported.
          items:
            $ref: "#/components/schemas/ChatCompletionTool"
          type: array
        tool_choice:
          $ref: "#/components/schemas/ChatCompletionToolChoiceOption"
        user:
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
          example: user-1234
          type: string
        function_call:
          $ref: "#/components/schemas/CreateChatCompletionRequest_function_call"
        functions:
          deprecated: true
          description: |
            Deprecated in favor of `tools`.

            A list of functions the model may generate JSON inputs for.
          items:
            $ref: "#/components/schemas/ChatCompletionFunctions"
          maxItems: 128
          minItems: 1
          type: array
      required:
      - messages
      - model
      type: object
    CreateChatCompletionResponse:
      description: "Represents a chat completion response returned by model, based\
        \ on the provided input."
      example:
        created: 2
        usage:
          completion_tokens: 7
          prompt_tokens: 9
          total_tokens: 3
        model: model
        id: id
        choices:
        - finish_reason: stop
          index: 0
          message:
            role: assistant
            function_call:
              name: name
              arguments: arguments
            tool_calls:
            - function:
                name: name
                arguments: arguments
              id: id
              type: function
            - function:
                name: name
                arguments: arguments
              id: id
              type: function
            content: content
          logprobs:
            content:
            - top_logprobs:
              - logprob: 5.962133916683182
                bytes:
                - 5
                - 5
                token: token
              - logprob: 5.962133916683182
                bytes:
                - 5
                - 5
                token: token
              logprob: 6.027456183070403
              bytes:
              - 1
              - 1
              token: token
            - top_logprobs:
              - logprob: 5.962133916683182
                bytes:
                - 5
                - 5
                token: token
              - logprob: 5.962133916683182
                bytes:
                - 5
                - 5
                token: token
              logprob: 6.027456183070403
              bytes:
              - 1
              - 1
              token: token
        - finish_reason: stop
          index: 0
          message:
            role: assistant
            function_call:
              name: name
              arguments: arguments
            tool_calls:
            - function:
                name: name
                arguments: arguments
              id: id
              type: function
            - function:
                name: name
                arguments: arguments
              id: id
              type: function
            content: content
          logprobs:
            content:
            - top_logprobs:
              - logprob: 5.962133916683182
                bytes:
                - 5
                - 5
                token: token
              - logprob: 5.962133916683182
                bytes:
                - 5
                - 5
                token: token
              logprob: 6.027456183070403
              bytes:
              - 1
              - 1
              token: token
            - top_logprobs:
              - logprob: 5.962133916683182
                bytes:
                - 5
                - 5
                token: token
              - logprob: 5.962133916683182
                bytes:
                - 5
                - 5
                token: token
              logprob: 6.027456183070403
              bytes:
              - 1
              - 1
              token: token
        system_fingerprint: system_fingerprint
        object: chat.completion
      properties:
        id:
          description: A unique identifier for the chat completion.
          type: string
        choices:
          description: A list of chat completion choices. Can be more than one if
            `n` is greater than 1.
          items:
            $ref: "#/components/schemas/CreateChatCompletionResponse_choices_inner"
          type: array
        created:
          description: The Unix timestamp (in seconds) of when the chat completion
            was created.
          type: integer
        model:
          description: The model used for the chat completion.
          type: string
        system_fingerprint:
          description: |
            This fingerprint represents the backend configuration that the model runs with.

            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
          type: string
        object:
          description: "The object type, which is always `chat.completion`."
          enum:
          - chat.completion
          type: string
        usage:
          $ref: "#/components/schemas/CompletionUsage"
      required:
      - choices
      - created
      - id
      - model
      - object
      type: object
      x-oaiMeta:
        name: The chat completion object
        group: chat
        example: |
          {
            "id": "chatcmpl-123",
            "object": "chat.completion",
            "created": 1677652288,
            "model": "gpt-3.5-turbo-0125",
            "system_fingerprint": "fp_44709d6fcb",
            "choices": [{
              "index": 0,
              "message": {
                "role": "assistant",
                "content": "\n\nHello there, how may I assist you today?",
              },
              "logprobs": null,
              "finish_reason": "stop"
            }],
            "usage": {
              "prompt_tokens": 9,
              "completion_tokens": 12,
              "total_tokens": 21
            }
          }
    CreateChatCompletionFunctionResponse:
      description: "Represents a chat completion response returned by model, based\
        \ on the provided input."
      properties:
        id:
          description: A unique identifier for the chat completion.
          type: string
        choices:
          description: A list of chat completion choices. Can be more than one if
            `n` is greater than 1.
          items:
            $ref: "#/components/schemas/CreateChatCompletionFunctionResponse_choices_inner"
          type: array
        created:
          description: The Unix timestamp (in seconds) of when the chat completion
            was created.
          type: integer
        model:
          description: The model used for the chat completion.
          type: string
        system_fingerprint:
          description: |
            This fingerprint represents the backend configuration that the model runs with.

            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
          type: string
        object:
          description: "The object type, which is always `chat.completion`."
          enum:
          - chat.completion
          type: string
        usage:
          $ref: "#/components/schemas/CompletionUsage"
      required:
      - choices
      - created
      - id
      - model
      - object
      type: object
      x-oaiMeta:
        name: The chat completion object
        group: chat
        example: |
          {
            "id": "chatcmpl-abc123",
            "object": "chat.completion",
            "created": 1699896916,
            "model": "gpt-3.5-turbo-0125",
            "choices": [
              {
                "index": 0,
                "message": {
                  "role": "assistant",
                  "content": null,
                  "tool_calls": [
                    {
                      "id": "call_abc123",
                      "type": "function",
                      "function": {
                        "name": "get_current_weather",
                        "arguments": "{\n\"location\": \"Boston, MA\"\n}"
                      }
                    }
                  ]
                },
                "logprobs": null,
                "finish_reason": "tool_calls"
              }
            ],
            "usage": {
              "prompt_tokens": 82,
              "completion_tokens": 17,
              "total_tokens": 99
            }
          }
    ChatCompletionTokenLogprob:
      example:
        top_logprobs:
        - logprob: 5.962133916683182
          bytes:
          - 5
          - 5
          token: token
        - logprob: 5.962133916683182
          bytes:
          - 5
          - 5
          token: token
        logprob: 6.027456183070403
        bytes:
        - 1
        - 1
        token: token
      properties:
        token:
          description: The token.
          type: string
        logprob:
          description: "The log probability of this token, if it is within the top\
            \ 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify\
            \ that the token is very unlikely."
          type: number
        bytes:
          description: A list of integers representing the UTF-8 bytes representation
            of the token. Useful in instances where characters are represented by
            multiple tokens and their byte representations must be combined to generate
            the correct text representation. Can be `null` if there is no bytes representation
            for the token.
          items:
            type: integer
          nullable: true
          type: array
        top_logprobs:
          description: "List of the most likely tokens and their log probability,\
            \ at this token position. In rare cases, there may be fewer than the number\
            \ of requested `top_logprobs` returned."
          items:
            $ref: "#/components/schemas/ChatCompletionTokenLogprob_top_logprobs_inner"
          type: array
      required:
      - bytes
      - logprob
      - token
      - top_logprobs
      type: object
    CreateChatCompletionStreamResponse:
      description: "Represents a streamed chunk of a chat completion response returned\
        \ by model, based on the provided input."
      properties:
        id:
          description: A unique identifier for the chat completion. Each chunk has
            the same ID.
          type: string
        choices:
          description: |
            A list of chat completion choices. Can contain more than one elements if `n` is greater than 1. Can also be empty for the
            last chunk if you set `stream_options: {"include_usage": true}`.
          items:
            $ref: "#/components/schemas/CreateChatCompletionStreamResponse_choices_inner"
          type: array
        created:
          description: The Unix timestamp (in seconds) of when the chat completion
            was created. Each chunk has the same timestamp.
          type: integer
        model:
          description: The model to generate the completion.
          type: string
        system_fingerprint:
          description: |
            This fingerprint represents the backend configuration that the model runs with.
            Can be used in conjunction with the `seed` request parameter to understand when backend changes have been made that might impact determinism.
          type: string
        object:
          description: "The object type, which is always `chat.completion.chunk`."
          enum:
          - chat.completion.chunk
          type: string
        usage:
          $ref: "#/components/schemas/CreateChatCompletionStreamResponse_usage"
      required:
      - choices
      - created
      - id
      - model
      - object
      type: object
      x-oaiMeta:
        name: The chat completion chunk object
        group: chat
        example: |
          {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0125", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}

          {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0125", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}

          ....

          {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0125", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
    CreateChatCompletionImageResponse:
      description: "Represents a streamed chunk of a chat completion response returned\
        \ by model, based on the provided input."
      type: object
      x-oaiMeta:
        name: The chat completion chunk object
        group: chat
        example: |
          {
            "id": "chatcmpl-123",
            "object": "chat.completion",
            "created": 1677652288,
            "model": "gpt-3.5-turbo-0125",
            "system_fingerprint": "fp_44709d6fcb",
            "choices": [{
              "index": 0,
              "message": {
                "role": "assistant",
                "content": "\n\nThis image shows a wooden boardwalk extending through a lush green marshland.",
              },
              "logprobs": null,
              "finish_reason": "stop"
            }],
            "usage": {
              "prompt_tokens": 9,
              "completion_tokens": 12,
              "total_tokens": 21
            }
          }
    ImagesResponse:
      properties:
        created:
          type: integer
        data:
          items:
            $ref: "#/components/schemas/Image"
          type: array
      required:
      - created
      - data
    Image:
      description: Represents the url or the content of an image generated by the
        OpenAI API.
      properties:
        b64_json:
          description: "The base64-encoded JSON of the generated image, if `response_format`\
            \ is `b64_json`."
          type: string
        url:
          description: "The URL of the generated image, if `response_format` is `url`\
            \ (default)."
          type: string
        revised_prompt:
          description: "The prompt that was used to generate the image, if there was\
            \ any revision to the prompt."
          type: string
      type: object
      x-oaiMeta:
        name: The image object
        example: |
          {
            "url": "...",
            "revised_prompt": "..."
          }
    CreateImageEditRequest:
      properties:
        image:
          description: "The image to edit. Must be a valid PNG file, less than 4MB,\
            \ and square. If mask is not provided, image must have transparency, which\
            \ will be used as the mask."
          format: binary
          type: string
        prompt:
          description: A text description of the desired image(s). The maximum length
            is 1000 characters.
          example: A cute baby sea otter wearing a beret
          type: string
        mask:
          description: "An additional image whose fully transparent areas (e.g. where\
            \ alpha is zero) indicate where `image` should be edited. Must be a valid\
            \ PNG file, less than 4MB, and have the same dimensions as `image`."
          format: binary
          type: string
        model:
          $ref: "#/components/schemas/CreateImageEditRequest_model"
        "n":
          default: 1
          description: The number of images to generate. Must be between 1 and 10.
          example: 1
          maximum: 10
          minimum: 1
          nullable: true
          type: integer
        size:
          default: 1024x1024
          description: "The size of the generated images. Must be one of `256x256`,\
            \ `512x512`, or `1024x1024`."
          enum:
          - 256x256
          - 512x512
          - 1024x1024
          example: 1024x1024
          nullable: true
          type: string
        response_format:
          default: url
          description: The format in which the generated images are returned. Must
            be one of `url` or `b64_json`. URLs are only valid for 60 minutes after
            the image has been generated.
          enum:
          - url
          - b64_json
          example: url
          nullable: true
          type: string
        user:
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
          example: user-1234
          type: string
      required:
      - image
      - prompt
      type: object
    CreateImageVariationRequest:
      properties:
        image:
          description: "The image to use as the basis for the variation(s). Must be\
            \ a valid PNG file, less than 4MB, and square."
          format: binary
          type: string
        model:
          $ref: "#/components/schemas/CreateImageEditRequest_model"
        "n":
          default: 1
          description: "The number of images to generate. Must be between 1 and 10.\
            \ For `dall-e-3`, only `n=1` is supported."
          example: 1
          maximum: 10
          minimum: 1
          nullable: true
          type: integer
        response_format:
          default: url
          description: The format in which the generated images are returned. Must
            be one of `url` or `b64_json`. URLs are only valid for 60 minutes after
            the image has been generated.
          enum:
          - url
          - b64_json
          example: url
          nullable: true
          type: string
        size:
          default: 1024x1024
          description: "The size of the generated images. Must be one of `256x256`,\
            \ `512x512`, or `1024x1024`."
          enum:
          - 256x256
          - 512x512
          - 1024x1024
          example: 1024x1024
          nullable: true
          type: string
        user:
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
          example: user-1234
          type: string
      required:
      - image
      type: object
    CreateModerationRequest:
      properties:
        input:
          $ref: "#/components/schemas/CreateModerationRequest_input"
        model:
          $ref: "#/components/schemas/CreateModerationRequest_model"
      required:
      - input
      type: object
    CreateModerationResponse:
      description: Represents if a given text input is potentially harmful.
      properties:
        id:
          description: The unique identifier for the moderation request.
          type: string
        model:
          description: The model used to generate the moderation results.
          type: string
        results:
          description: A list of moderation objects.
          items:
            $ref: "#/components/schemas/CreateModerationResponse_results_inner"
          type: array
      required:
      - id
      - model
      - results
      type: object
      x-oaiMeta:
        name: The moderation object
        example: |
          {
            "id": "modr-XXXXX",
            "model": "text-moderation-005",
            "results": [
              {
                "flagged": true,
                "categories": {
                  "sexual": false,
                  "hate": false,
                  "harassment": false,
                  "self-harm": false,
                  "sexual/minors": false,
                  "hate/threatening": false,
                  "violence/graphic": false,
                  "self-harm/intent": false,
                  "self-harm/instructions": false,
                  "harassment/threatening": true,
                  "violence": true,
                },
                "category_scores": {
                  "sexual": 1.2282071e-06,
                  "hate": 0.010696256,
                  "harassment": 0.29842457,
                  "self-harm": 1.5236925e-08,
                  "sexual/minors": 5.7246268e-08,
                  "hate/threatening": 0.0060676364,
                  "violence/graphic": 4.435014e-06,
                  "self-harm/intent": 8.098441e-10,
                  "self-harm/instructions": 2.8498655e-11,
                  "harassment/threatening": 0.63055265,
                  "violence": 0.99011886,
                }
              }
            ]
          }
    ListFilesResponse:
      properties:
        data:
          items:
            $ref: "#/components/schemas/OpenAIFile"
          type: array
        object:
          enum:
          - list
          type: string
      required:
      - data
      - object
      type: object
    CreateFileRequest:
      additionalProperties: false
      properties:
        file:
          description: |
            The File object (not file name) to be uploaded.
          format: binary
          type: string
        purpose:
          description: |
            The intended purpose of the uploaded file.

            Use "assistants" for [Assistants](/docs/api-reference/assistants) and [Message](/docs/api-reference/messages) files, "vision" for Assistants image file inputs, "batch" for [Batch API](/docs/guides/batch), and "fine-tune" for [Fine-tuning](/docs/api-reference/fine-tuning).
          enum:
          - assistants
          - batch
          - fine-tune
          - vision
          type: string
      required:
      - file
      - purpose
      type: object
    DeleteFileResponse:
      properties:
        id:
          type: string
        object:
          enum:
          - file
          type: string
        deleted:
          type: boolean
      required:
      - deleted
      - id
      - object
      type: object
    CreateFineTuningJobRequest:
      properties:
        model:
          $ref: "#/components/schemas/CreateFineTuningJobRequest_model"
        training_file:
          description: |
            The ID of an uploaded file that contains training data.

            See [upload file](/docs/api-reference/files/create) for how to upload a file.

            Your dataset must be formatted as a JSONL file. Additionally, you must upload your file with the purpose `fine-tune`.

            See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.
          example: file-abc123
          type: string
        hyperparameters:
          $ref: "#/components/schemas/CreateFineTuningJobRequest_hyperparameters"
        suffix:
          description: |
            A string of up to 18 characters that will be added to your fine-tuned model name.

            For example, a `suffix` of "custom-model-name" would produce a model name like `ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel`.
          maxLength: 40
          minLength: 1
          nullable: true
          type: string
        validation_file:
          description: |
            The ID of an uploaded file that contains validation data.

            If you provide this file, the data is used to generate validation
            metrics periodically during fine-tuning. These metrics can be viewed in
            the fine-tuning results file.
            The same data should not be present in both train and validation files.

            Your dataset must be formatted as a JSONL file. You must upload your file with the purpose `fine-tune`.

            See the [fine-tuning guide](/docs/guides/fine-tuning) for more details.
          example: file-abc123
          nullable: true
          type: string
        integrations:
          description: A list of integrations to enable for your fine-tuning job.
          items:
            $ref: "#/components/schemas/CreateFineTuningJobRequest_integrations_inner"
          nullable: true
          type: array
        seed:
          description: |
            The seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but may differ in rare cases.
            If a seed is not specified, one will be generated for you.
          example: 42
          maximum: 2147483647
          minimum: 0
          nullable: true
          type: integer
      required:
      - model
      - training_file
      type: object
    ListFineTuningJobEventsResponse:
      properties:
        data:
          items:
            $ref: "#/components/schemas/FineTuningJobEvent"
          type: array
        object:
          enum:
          - list
          type: string
      required:
      - data
      - object
      type: object
    ListFineTuningJobCheckpointsResponse:
      properties:
        data:
          items:
            $ref: "#/components/schemas/FineTuningJobCheckpoint"
          type: array
        object:
          enum:
          - list
          type: string
        first_id:
          nullable: true
          type: string
        last_id:
          nullable: true
          type: string
        has_more:
          type: boolean
      required:
      - data
      - has_more
      - object
      type: object
    CreateEmbeddingRequest:
      additionalProperties: false
      example:
        input: The quick brown fox jumped over the lazy dog
        encoding_format: float
        model: text-embedding-3-small
        user: user-1234
        dimensions: 1
      properties:
        input:
          $ref: "#/components/schemas/CreateEmbeddingRequest_input"
        model:
          $ref: "#/components/schemas/CreateEmbeddingRequest_model"
        encoding_format:
          default: float
          description: "The format to return the embeddings in. Can be either `float`\
            \ or [`base64`](https://pypi.org/project/pybase64/)."
          enum:
          - float
          - base64
          example: float
          type: string
        dimensions:
          description: |
            The number of dimensions the resulting output embeddings should have. Only supported in `text-embedding-3` and later models.
          minimum: 1
          type: integer
        user:
          description: |
            A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse. [Learn more](/docs/guides/safety-best-practices/end-user-ids).
          example: user-1234
          type: string
      required:
      - input
      - model
      type: object
    CreateEmbeddingResponse:
      example:
        data:
        - index: 0
          embedding:
          - 6.027456183070403
          - 6.027456183070403
          object: embedding
        - index: 0
          embedding:
          - 6.027456183070403
          - 6.027456183070403
          object: embedding
        usage:
          prompt_tokens: 1
          total_tokens: 5
        model: model
        object: list
      properties:
        data:
          description: The list of embeddings generated by the model.
          items:
            $ref: "#/components/schemas/Embedding"
          type: array
        model:
          description: The name of the model used to generate the embedding.
          type: string
        object:
          description: "The object type, which is always \"list\"."
          enum:
          - list
          type: string
        usage:
          $ref: "#/components/schemas/CreateEmbeddingResponse_usage"
      required:
      - data
      - model
      - object
      - usage
      type: object
    CreateTranscriptionRequest:
      additionalProperties: false
      properties:
        file:
          description: |
            The audio file object (not file name) to transcribe, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.
          format: binary
          type: string
          x-oaiTypeLabel: file
        model:
          $ref: "#/components/schemas/CreateTranscriptionRequest_model"
        language:
          description: |
            The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.
          type: string
        prompt:
          description: |
            An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should match the audio language.
          type: string
        response_format:
          default: json
          description: |
            The format of the transcript output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.
          enum:
          - json
          - text
          - srt
          - verbose_json
          - vtt
          type: string
        temperature:
          default: 0
          description: |
            The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.
          type: number
        timestamp_granularities[]:
          default:
          - segment
          description: |
            The timestamp granularities to populate for this transcription. `response_format` must be set `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.
          items:
            enum:
            - word
            - segment
            type: string
          type: array
      required:
      - file
      - model
      type: object
    CreateTranscriptionResponseJson:
      description: "Represents a transcription response returned by model, based on\
        \ the provided input."
      properties:
        text:
          description: The transcribed text.
          type: string
      required:
      - text
      type: object
      x-oaiMeta:
        name: The transcription object (JSON)
        group: audio
        example: |
          {
            "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
          }
    TranscriptionSegment:
      properties:
        id:
          description: Unique identifier of the segment.
          type: integer
        seek:
          description: Seek offset of the segment.
          type: integer
        start:
          description: Start time of the segment in seconds.
          format: float
          type: number
        end:
          description: End time of the segment in seconds.
          format: float
          type: number
        text:
          description: Text content of the segment.
          type: string
        tokens:
          description: Array of token IDs for the text content.
          items:
            type: integer
          type: array
        temperature:
          description: Temperature parameter used for generating the segment.
          format: float
          type: number
        avg_logprob:
          description: "Average logprob of the segment. If the value is lower than\
            \ -1, consider the logprobs failed."
          format: float
          type: number
        compression_ratio:
          description: "Compression ratio of the segment. If the value is greater\
            \ than 2.4, consider the compression failed."
          format: float
          type: number
        no_speech_prob:
          description: "Probability of no speech in the segment. If the value is higher\
            \ than 1.0 and the `avg_logprob` is below -1, consider this segment silent."
          format: float
          type: number
      required:
      - avg_logprob
      - compression_ratio
      - end
      - id
      - no_speech_prob
      - seek
      - start
      - temperature
      - text
      - tokens
      type: object
    TranscriptionWord:
      properties:
        word:
          description: The text content of the word.
          type: string
        start:
          description: Start time of the word in seconds.
          format: float
          type: number
        end:
          description: End time of the word in seconds.
          format: float
          type: number
      required:
      - end
      - start
      - word
      type: object
    CreateTranscriptionResponseVerboseJson:
      description: "Represents a verbose json transcription response returned by model,\
        \ based on the provided input."
      properties:
        language:
          description: The language of the input audio.
          type: string
        duration:
          description: The duration of the input audio.
          type: string
        text:
          description: The transcribed text.
          type: string
        words:
          description: Extracted words and their corresponding timestamps.
          items:
            $ref: "#/components/schemas/TranscriptionWord"
          type: array
        segments:
          description: Segments of the transcribed text and their corresponding details.
          items:
            $ref: "#/components/schemas/TranscriptionSegment"
          type: array
      required:
      - duration
      - language
      - text
      type: object
      x-oaiMeta:
        name: The transcription object (Verbose JSON)
        group: audio
        example: |
          {
            "task": "transcribe",
            "language": "english",
            "duration": 8.470000267028809,
            "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
            "segments": [
              {
                "id": 0,
                "seek": 0,
                "start": 0.0,
                "end": 3.319999933242798,
                "text": " The beach was a popular spot on a hot summer day.",
                "tokens": [
                  50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530
                ],
                "temperature": 0.0,
                "avg_logprob": -0.2860786020755768,
                "compression_ratio": 1.2363636493682861,
                "no_speech_prob": 0.00985979475080967
              },
              ...
            ]
          }
    CreateTranslationRequest:
      additionalProperties: false
      properties:
        file:
          description: |
            The audio file object (not file name) translate, in one of these formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.
          format: binary
          type: string
          x-oaiTypeLabel: file
        model:
          $ref: "#/components/schemas/CreateTranscriptionRequest_model"
        prompt:
          description: |
            An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should be in English.
          type: string
        response_format:
          default: json
          description: |
            The format of the transcript output, in one of these options: `json`, `text`, `srt`, `verbose_json`, or `vtt`.
          type: string
        temperature:
          default: 0
          description: |
            The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.
          type: number
      required:
      - file
      - model
      type: object
    CreateTranslationResponseJson:
      properties:
        text:
          type: string
      required:
      - text
      type: object
    CreateTranslationResponseVerboseJson:
      properties:
        language:
          description: The language of the output translation (always `english`).
          type: string
        duration:
          description: The duration of the input audio.
          type: string
        text:
          description: The translated text.
          type: string
        segments:
          description: Segments of the translated text and their corresponding details.
          items:
            $ref: "#/components/schemas/TranscriptionSegment"
          type: array
      required:
      - duration
      - language
      - text
      type: object
    CreateSpeechRequest:
      additionalProperties: false
      properties:
        model:
          $ref: "#/components/schemas/CreateSpeechRequest_model"
        input:
          description: The text to generate audio for. The maximum length is 4096
            characters.
          maxLength: 4096
          type: string
        voice:
          description: "The voice to use when generating the audio. Supported voices\
            \ are `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`. Previews\
            \ of the voices are available in the [Text to speech guide](/docs/guides/text-to-speech/voice-options)."
          enum:
          - alloy
          - echo
          - fable
          - onyx
          - nova
          - shimmer
          type: string
        response_format:
          default: mp3
          description: "The format to audio in. Supported formats are `mp3`, `opus`,\
            \ `aac`, `flac`, `wav`, and `pcm`."
          enum:
          - mp3
          - opus
          - aac
          - flac
          - wav
          - pcm
          type: string
        speed:
          default: 1
          description: The speed of the generated audio. Select a value from `0.25`
            to `4.0`. `1.0` is the default.
          maximum: 4
          minimum: 0.25
          type: number
      required:
      - input
      - model
      - voice
      type: object
    Model:
      description: Describes an OpenAI model offering that can be used with the API.
      properties:
        id:
          description: "The model identifier, which can be referenced in the API endpoints."
          type: string
        created:
          description: The Unix timestamp (in seconds) when the model was created.
          type: integer
        object:
          description: "The object type, which is always \"model\"."
          enum:
          - model
          type: string
        owned_by:
          description: The organization that owns the model.
          type: string
      required:
      - created
      - id
      - object
      - owned_by
      title: Model
      x-oaiMeta:
        name: The model object
        example: |
          {
            "id": "VAR_model_id",
            "object": "model",
            "created": 1686935002,
            "owned_by": "openai"
          }
    OpenAIFile:
      description: The `File` object represents a document that has been uploaded
        to OpenAI.
      properties:
        id:
          description: "The file identifier, which can be referenced in the API endpoints."
          type: string
        bytes:
          description: "The size of the file, in bytes."
          type: integer
        created_at:
          description: The Unix timestamp (in seconds) for when the file was created.
          type: integer
        filename:
          description: The name of the file.
          type: string
        object:
          description: "The object type, which is always `file`."
          enum:
          - file
          type: string
        purpose:
          description: "The intended purpose of the file. Supported values are `assistants`,\
            \ `assistants_output`, `batch`, `batch_output`, `fine-tune`, `fine-tune-results`\
            \ and `vision`."
          enum:
          - assistants
          - assistants_output
          - batch
          - batch_output
          - fine-tune
          - fine-tune-results
          - vision
          type: string
        status:
          deprecated: true
          description: "Deprecated. The current status of the file, which can be either\
            \ `uploaded`, `processed`, or `error`."
          enum:
          - uploaded
          - processed
          - error
          type: string
        status_details:
          deprecated: true
          description: "Deprecated. For details on why a fine-tuning training file\
            \ failed validation, see the `error` field on `fine_tuning.job`."
          type: string
      required:
      - bytes
      - created_at
      - filename
      - id
      - object
      - purpose
      - status
      title: OpenAIFile
      x-oaiMeta:
        name: The file object
        example: |
          {
            "id": "file-abc123",
            "object": "file",
            "bytes": 120000,
            "created_at": 1677610602,
            "filename": "salesOverview.pdf",
            "purpose": "assistants",
          }
    Embedding:
      description: |
        Represents an embedding vector returned by embedding endpoint.
      example:
        index: 0
        embedding:
        - 6.027456183070403
        - 6.027456183070403
        object: embedding
      properties:
        index:
          description: The index of the embedding in the list of embeddings.
          type: integer
        embedding:
          description: |
            The embedding vector, which is a list of floats. The length of vector depends on the model as listed in the [embedding guide](/docs/guides/embeddings).
          items:
            type: number
          type: array
        object:
          description: "The object type, which is always \"embedding\"."
          enum:
          - embedding
          type: string
      required:
      - embedding
      - index
      - object
      type: object
      x-oaiMeta:
        name: The embedding object
        example: |
          {
            "object": "embedding",
            "embedding": [
              0.0023064255,
              -0.009327292,
              .... (1536 floats total for ada-002)
              -0.0028842222,
            ],
            "index": 0
          }
    FineTuningJob:
      description: |
        The `fine_tuning.job` object represents a fine-tuning job that has been created through the API.
      properties:
        id:
          description: "The object identifier, which can be referenced in the API\
            \ endpoints."
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the fine-tuning job
            was created.
          type: integer
        error:
          $ref: "#/components/schemas/FineTuningJob_error"
        fine_tuned_model:
          description: The name of the fine-tuned model that is being created. The
            value will be null if the fine-tuning job is still running.
          nullable: true
          type: string
        finished_at:
          description: The Unix timestamp (in seconds) for when the fine-tuning job
            was finished. The value will be null if the fine-tuning job is still running.
          nullable: true
          type: integer
        hyperparameters:
          $ref: "#/components/schemas/FineTuningJob_hyperparameters"
        model:
          description: The base model that is being fine-tuned.
          type: string
        object:
          description: "The object type, which is always \"fine_tuning.job\"."
          enum:
          - fine_tuning.job
          type: string
        organization_id:
          description: The organization that owns the fine-tuning job.
          type: string
        result_files:
          description: "The compiled results file ID(s) for the fine-tuning job. You\
            \ can retrieve the results with the [Files API](/docs/api-reference/files/retrieve-contents)."
          items:
            example: file-abc123
            type: string
          type: array
        status:
          description: "The current status of the fine-tuning job, which can be either\
            \ `validating_files`, `queued`, `running`, `succeeded`, `failed`, or `cancelled`."
          enum:
          - validating_files
          - queued
          - running
          - succeeded
          - failed
          - cancelled
          type: string
        trained_tokens:
          description: The total number of billable tokens processed by this fine-tuning
            job. The value will be null if the fine-tuning job is still running.
          nullable: true
          type: integer
        training_file:
          description: "The file ID used for training. You can retrieve the training\
            \ data with the [Files API](/docs/api-reference/files/retrieve-contents)."
          type: string
        validation_file:
          description: "The file ID used for validation. You can retrieve the validation\
            \ results with the [Files API](/docs/api-reference/files/retrieve-contents)."
          nullable: true
          type: string
        integrations:
          description: A list of integrations to enable for this fine-tuning job.
          items:
            $ref: "#/components/schemas/FineTuningJob_integrations_inner"
          maxItems: 5
          nullable: true
          type: array
        seed:
          description: The seed used for the fine-tuning job.
          type: integer
        estimated_finish:
          description: The Unix timestamp (in seconds) for when the fine-tuning job
            is estimated to finish. The value will be null if the fine-tuning job
            is not running.
          nullable: true
          type: integer
      required:
      - created_at
      - error
      - fine_tuned_model
      - finished_at
      - hyperparameters
      - id
      - model
      - object
      - organization_id
      - result_files
      - seed
      - status
      - trained_tokens
      - training_file
      - validation_file
      title: FineTuningJob
      type: object
      x-oaiMeta:
        name: The fine-tuning job object
        example: |
          {
            "object": "fine_tuning.job",
            "id": "ftjob-abc123",
            "model": "davinci-002",
            "created_at": 1692661014,
            "finished_at": 1692661190,
            "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
            "organization_id": "org-123",
            "result_files": [
                "file-abc123"
            ],
            "status": "succeeded",
            "validation_file": null,
            "training_file": "file-abc123",
            "hyperparameters": {
                "n_epochs": 4,
                "batch_size": 1,
                "learning_rate_multiplier": 1.0
            },
            "trained_tokens": 5768,
            "integrations": [],
            "seed": 0,
            "estimated_finish": 0
          }
    FineTuningIntegration:
      properties:
        type:
          description: The type of the integration being enabled for the fine-tuning
            job
          enum:
          - wandb
          type: string
        wandb:
          $ref: "#/components/schemas/CreateFineTuningJobRequest_integrations_inner_wandb"
      required:
      - type
      - wandb
      title: Fine-Tuning Job Integration
      type: object
    FineTuningJobEvent:
      description: Fine-tuning job event object
      properties:
        id:
          type: string
        created_at:
          type: integer
        level:
          enum:
          - info
          - warn
          - error
          type: string
        message:
          type: string
        object:
          enum:
          - fine_tuning.job.event
          type: string
      required:
      - created_at
      - id
      - level
      - message
      - object
      type: object
      x-oaiMeta:
        name: The fine-tuning job event object
        example: |
          {
            "object": "fine_tuning.job.event",
            "id": "ftevent-abc123"
            "created_at": 1677610602,
            "level": "info",
            "message": "Created fine-tuning job"
          }
    FineTuningJobCheckpoint:
      description: |
        The `fine_tuning.job.checkpoint` object represents a model checkpoint for a fine-tuning job that is ready to use.
      properties:
        id:
          description: "The checkpoint identifier, which can be referenced in the\
            \ API endpoints."
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the checkpoint was
            created.
          type: integer
        fine_tuned_model_checkpoint:
          description: The name of the fine-tuned checkpoint model that is created.
          type: string
        step_number:
          description: The step number that the checkpoint was created at.
          type: integer
        metrics:
          $ref: "#/components/schemas/FineTuningJobCheckpoint_metrics"
        fine_tuning_job_id:
          description: The name of the fine-tuning job that this checkpoint was created
            from.
          type: string
        object:
          description: "The object type, which is always \"fine_tuning.job.checkpoint\"\
            ."
          enum:
          - fine_tuning.job.checkpoint
          type: string
      required:
      - created_at
      - fine_tuned_model_checkpoint
      - fine_tuning_job_id
      - id
      - metrics
      - object
      - step_number
      title: FineTuningJobCheckpoint
      type: object
      x-oaiMeta:
        name: The fine-tuning job checkpoint object
        example: |
          {
            "object": "fine_tuning.job.checkpoint",
            "id": "ftckpt_qtZ5Gyk4BLq1SfLFWp3RtO3P",
            "created_at": 1712211699,
            "fine_tuned_model_checkpoint": "ft:gpt-3.5-turbo-0125:my-org:custom_suffix:9ABel2dg:ckpt-step-88",
            "fine_tuning_job_id": "ftjob-fpbNQ3H1GrMehXRf8cO97xTN",
            "metrics": {
              "step": 88,
              "train_loss": 0.478,
              "train_mean_token_accuracy": 0.924,
              "valid_loss": 10.112,
              "valid_mean_token_accuracy": 0.145,
              "full_valid_loss": 0.567,
              "full_valid_mean_token_accuracy": 0.944
            },
            "step_number": 88
          }
    CompletionUsage:
      description: Usage statistics for the completion request.
      example:
        completion_tokens: 7
        prompt_tokens: 9
        total_tokens: 3
      properties:
        completion_tokens:
          description: Number of tokens in the generated completion.
          type: integer
        prompt_tokens:
          description: Number of tokens in the prompt.
          type: integer
        total_tokens:
          description: Total number of tokens used in the request (prompt + completion).
          type: integer
      required:
      - completion_tokens
      - prompt_tokens
      - total_tokens
      type: object
    RunCompletionUsage:
      description: "Usage statistics related to the run. This value will be `null`\
        \ if the run is not in a terminal state (i.e. `in_progress`, `queued`, etc.)."
      nullable: true
      properties:
        completion_tokens:
          description: Number of completion tokens used over the course of the run.
          type: integer
        prompt_tokens:
          description: Number of prompt tokens used over the course of the run.
          type: integer
        total_tokens:
          description: Total number of tokens used (prompt + completion).
          type: integer
      required:
      - completion_tokens
      - prompt_tokens
      - total_tokens
      type: object
    RunStepCompletionUsage:
      description: Usage statistics related to the run step. This value will be `null`
        while the run step's status is `in_progress`.
      nullable: true
      properties:
        completion_tokens:
          description: Number of completion tokens used over the course of the run
            step.
          type: integer
        prompt_tokens:
          description: Number of prompt tokens used over the course of the run step.
          type: integer
        total_tokens:
          description: Total number of tokens used (prompt + completion).
          type: integer
      required:
      - completion_tokens
      - prompt_tokens
      - total_tokens
      type: object
    AssistantsApiResponseFormatOption:
      description: |
        Specifies the format that the model must output. Compatible with [GPT-4o](/docs/models/gpt-4o), [GPT-4 Turbo](/docs/models/gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models since `gpt-3.5-turbo-1106`.

        Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

        **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.
      oneOf:
      - description: |
          `auto` is the default value
        enum:
        - none
        - auto
        type: string
      - $ref: "#/components/schemas/AssistantsApiResponseFormat"
      x-oaiExpandable: true
    AssistantsApiResponseFormat:
      description: |
        An object describing the expected output of the model. If `json_object` only `function` type `tools` are allowed to be passed to the Run. If `text` the model can return text or any value needed.
      properties:
        type:
          default: text
          description: Must be one of `text` or `json_object`.
          enum:
          - text
          - json_object
          example: json_object
          type: string
      type: object
    AssistantObject:
      description: Represents an `assistant` that can call the model and use tools.
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints."
          type: string
        object:
          description: "The object type, which is always `assistant`."
          enum:
          - assistant
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the assistant was
            created.
          type: integer
        name:
          description: |
            The name of the assistant. The maximum length is 256 characters.
          maxLength: 256
          nullable: true
          type: string
        description:
          description: |
            The description of the assistant. The maximum length is 512 characters.
          maxLength: 512
          nullable: true
          type: string
        model:
          description: |
            ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them.
          type: string
        instructions:
          description: |
            The system instructions that the assistant uses. The maximum length is 256,000 characters.
          maxLength: 256000
          nullable: true
          type: string
        tools:
          default: []
          description: |
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.
          items:
            $ref: "#/components/schemas/AssistantObject_tools_inner"
          maxItems: 128
          type: array
        tool_resources:
          $ref: "#/components/schemas/AssistantObject_tool_resources"
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
        temperature:
          default: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
          example: 1
          maximum: 2
          minimum: 0
          nullable: true
          type: number
        top_p:
          default: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both.
          example: 1
          maximum: 1
          minimum: 0
          nullable: true
          type: number
        response_format:
          $ref: "#/components/schemas/AssistantsApiResponseFormatOption"
      required:
      - created_at
      - description
      - id
      - instructions
      - metadata
      - model
      - name
      - object
      - tools
      title: Assistant
      type: object
      x-oaiMeta:
        name: The assistant object
        beta: true
        example: |
          {
            "id": "asst_abc123",
            "object": "assistant",
            "created_at": 1698984975,
            "name": "Math Tutor",
            "description": null,
            "model": "gpt-4-turbo",
            "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
            "tools": [
              {
                "type": "code_interpreter"
              }
            ],
            "metadata": {},
            "top_p": 1.0,
            "temperature": 1.0,
            "response_format": "auto"
          }
    CreateAssistantRequest:
      additionalProperties: false
      properties:
        model:
          $ref: "#/components/schemas/CreateAssistantRequest_model"
        name:
          description: |
            The name of the assistant. The maximum length is 256 characters.
          maxLength: 256
          nullable: true
          type: string
        description:
          description: |
            The description of the assistant. The maximum length is 512 characters.
          maxLength: 512
          nullable: true
          type: string
        instructions:
          description: |
            The system instructions that the assistant uses. The maximum length is 256,000 characters.
          maxLength: 256000
          nullable: true
          type: string
        tools:
          default: []
          description: |
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.
          items:
            $ref: "#/components/schemas/AssistantObject_tools_inner"
          maxItems: 128
          type: array
        tool_resources:
          $ref: "#/components/schemas/CreateAssistantRequest_tool_resources"
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
        temperature:
          default: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
          example: 1
          maximum: 2
          minimum: 0
          nullable: true
          type: number
        top_p:
          default: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both.
          example: 1
          maximum: 1
          minimum: 0
          nullable: true
          type: number
        response_format:
          $ref: "#/components/schemas/AssistantsApiResponseFormatOption"
      required:
      - model
      type: object
    ModifyAssistantRequest:
      additionalProperties: false
      properties:
        model:
          type: string
        name:
          description: |
            The name of the assistant. The maximum length is 256 characters.
          maxLength: 256
          nullable: true
          type: string
        description:
          description: |
            The description of the assistant. The maximum length is 512 characters.
          maxLength: 512
          nullable: true
          type: string
        instructions:
          description: |
            The system instructions that the assistant uses. The maximum length is 256,000 characters.
          maxLength: 256000
          nullable: true
          type: string
        tools:
          default: []
          description: |
            A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.
          items:
            $ref: "#/components/schemas/AssistantObject_tools_inner"
          maxItems: 128
          type: array
        tool_resources:
          $ref: "#/components/schemas/ModifyAssistantRequest_tool_resources"
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
        temperature:
          default: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
          example: 1
          maximum: 2
          minimum: 0
          nullable: true
          type: number
        top_p:
          default: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both.
          example: 1
          maximum: 1
          minimum: 0
          nullable: true
          type: number
        response_format:
          $ref: "#/components/schemas/AssistantsApiResponseFormatOption"
      type: object
    DeleteAssistantResponse:
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          enum:
          - assistant.deleted
          type: string
      required:
      - deleted
      - id
      - object
      type: object
    ListAssistantsResponse:
      properties:
        object:
          example: list
          type: string
        data:
          items:
            $ref: "#/components/schemas/AssistantObject"
          type: array
        first_id:
          example: asst_abc123
          type: string
        last_id:
          example: asst_abc456
          type: string
        has_more:
          example: false
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
      x-oaiMeta:
        name: List assistants response object
        group: chat
        example: |
          {
            "object": "list",
            "data": [
              {
                "id": "asst_abc123",
                "object": "assistant",
                "created_at": 1698982736,
                "name": "Coding Tutor",
                "description": null,
                "model": "gpt-4-turbo",
                "instructions": "You are a helpful assistant designed to make me better at coding!",
                "tools": [],
                "tool_resources": {},
                "metadata": {},
                "top_p": 1.0,
                "temperature": 1.0,
                "response_format": "auto"
              },
              {
                "id": "asst_abc456",
                "object": "assistant",
                "created_at": 1698982718,
                "name": "My Assistant",
                "description": null,
                "model": "gpt-4-turbo",
                "instructions": "You are a helpful assistant designed to make me better at coding!",
                "tools": [],
                "tool_resources": {},
                "metadata": {},
                "top_p": 1.0,
                "temperature": 1.0,
                "response_format": "auto"
              },
              {
                "id": "asst_abc789",
                "object": "assistant",
                "created_at": 1698982643,
                "name": null,
                "description": null,
                "model": "gpt-4-turbo",
                "instructions": null,
                "tools": [],
                "tool_resources": {},
                "metadata": {},
                "top_p": 1.0,
                "temperature": 1.0,
                "response_format": "auto"
              }
            ],
            "first_id": "asst_abc123",
            "last_id": "asst_abc789",
            "has_more": false
          }
    AssistantToolsCode:
      properties:
        type:
          description: "The type of tool being defined: `code_interpreter`"
          enum:
          - code_interpreter
          type: string
      required:
      - type
      title: Code interpreter tool
      type: object
    AssistantToolsFileSearch:
      properties:
        type:
          description: "The type of tool being defined: `file_search`"
          enum:
          - file_search
          type: string
      required:
      - type
      title: FileSearch tool
      type: object
    AssistantToolsFunction:
      properties:
        type:
          description: "The type of tool being defined: `function`"
          enum:
          - function
          type: string
        function:
          $ref: "#/components/schemas/FunctionObject"
      required:
      - function
      - type
      title: Function tool
      type: object
    TruncationObject:
      description: Controls for how a thread will be truncated prior to the run. Use
        this to control the intial context window of the run.
      properties:
        type:
          description: "The truncation strategy to use for the thread. The default\
            \ is `auto`. If set to `last_messages`, the thread will be truncated to\
            \ the n most recent messages in the thread. When set to `auto`, messages\
            \ in the middle of the thread will be dropped to fit the context length\
            \ of the model, `max_prompt_tokens`."
          enum:
          - auto
          - last_messages
          type: string
        last_messages:
          description: The number of most recent messages from the thread when constructing
            the context for the run.
          minimum: 1
          nullable: true
          type: integer
      required:
      - type
      title: Thread Truncation Controls
      type: object
    AssistantsApiToolChoiceOption:
      description: |
        Controls which (if any) tool is called by the model.
        `none` means the model will not call any tools and instead generates a message.
        `auto` is the default value and means the model can pick between generating a message or calling one or more tools.
        `required` means the model must call one or more tools before responding to the user.
        Specifying a particular tool like `{"type": "file_search"}` or `{"type": "function", "function": {"name": "my_function"}}` forces the model to call that tool.
      oneOf:
      - description: |
          `none` means the model will not call any tools and instead generates a message. `auto` means the model can pick between generating a message or calling one or more tools. `required` means the model must call one or more tools before responding to the user.
        enum:
        - none
        - auto
        - required
        type: string
      - $ref: "#/components/schemas/AssistantsNamedToolChoice"
      x-oaiExpandable: true
    AssistantsNamedToolChoice:
      description: Specifies a tool the model should use. Use to force the model to
        call a specific tool.
      properties:
        type:
          description: "The type of the tool. If type is `function`, the function\
            \ name must be set"
          enum:
          - function
          - code_interpreter
          - file_search
          type: string
        function:
          $ref: "#/components/schemas/ChatCompletionNamedToolChoice_function"
      required:
      - type
      type: object
    RunObject:
      description: "Represents an execution run on a [thread](/docs/api-reference/threads)."
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints."
          type: string
        object:
          description: "The object type, which is always `thread.run`."
          enum:
          - thread.run
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the run was created.
          type: integer
        thread_id:
          description: "The ID of the [thread](/docs/api-reference/threads) that was\
            \ executed on as a part of this run."
          type: string
        assistant_id:
          description: "The ID of the [assistant](/docs/api-reference/assistants)\
            \ used for execution of this run."
          type: string
        status:
          description: "The status of the run, which can be either `queued`, `in_progress`,\
            \ `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`,\
            \ `incomplete`, or `expired`."
          enum:
          - queued
          - in_progress
          - requires_action
          - cancelling
          - cancelled
          - failed
          - completed
          - incomplete
          - expired
          type: string
        required_action:
          $ref: "#/components/schemas/RunObject_required_action"
        last_error:
          $ref: "#/components/schemas/RunObject_last_error"
        expires_at:
          description: The Unix timestamp (in seconds) for when the run will expire.
          nullable: true
          type: integer
        started_at:
          description: The Unix timestamp (in seconds) for when the run was started.
          nullable: true
          type: integer
        cancelled_at:
          description: The Unix timestamp (in seconds) for when the run was cancelled.
          nullable: true
          type: integer
        failed_at:
          description: The Unix timestamp (in seconds) for when the run failed.
          nullable: true
          type: integer
        completed_at:
          description: The Unix timestamp (in seconds) for when the run was completed.
          nullable: true
          type: integer
        incomplete_details:
          $ref: "#/components/schemas/RunObject_incomplete_details"
        model:
          description: "The model that the [assistant](/docs/api-reference/assistants)\
            \ used for this run."
          type: string
        instructions:
          description: "The instructions that the [assistant](/docs/api-reference/assistants)\
            \ used for this run."
          type: string
        tools:
          default: []
          description: "The list of tools that the [assistant](/docs/api-reference/assistants)\
            \ used for this run."
          items:
            $ref: "#/components/schemas/AssistantObject_tools_inner"
          maxItems: 20
          type: array
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
        usage:
          $ref: "#/components/schemas/RunCompletionUsage"
        temperature:
          description: "The sampling temperature used for this run. If not set, defaults\
            \ to 1."
          nullable: true
          type: number
        top_p:
          description: "The nucleus sampling value used for this run. If not set,\
            \ defaults to 1."
          nullable: true
          type: number
        max_prompt_tokens:
          description: |
            The maximum number of prompt tokens specified to have been used over the course of the run.
          minimum: 256
          nullable: true
          type: integer
        max_completion_tokens:
          description: |
            The maximum number of completion tokens specified to have been used over the course of the run.
          minimum: 256
          nullable: true
          type: integer
        truncation_strategy:
          $ref: "#/components/schemas/TruncationObject"
        tool_choice:
          $ref: "#/components/schemas/AssistantsApiToolChoiceOption"
        response_format:
          $ref: "#/components/schemas/AssistantsApiResponseFormatOption"
      required:
      - assistant_id
      - cancelled_at
      - completed_at
      - created_at
      - expires_at
      - failed_at
      - id
      - incomplete_details
      - instructions
      - last_error
      - max_completion_tokens
      - max_prompt_tokens
      - metadata
      - model
      - object
      - required_action
      - response_format
      - started_at
      - status
      - thread_id
      - tool_choice
      - tools
      - truncation_strategy
      - usage
      title: A run on a thread
      type: object
      x-oaiMeta:
        name: The run object
        beta: true
        example: |
          {
            "id": "run_abc123",
            "object": "thread.run",
            "created_at": 1698107661,
            "assistant_id": "asst_abc123",
            "thread_id": "thread_abc123",
            "status": "completed",
            "started_at": 1699073476,
            "expires_at": null,
            "cancelled_at": null,
            "failed_at": null,
            "completed_at": 1699073498,
            "last_error": null,
            "model": "gpt-4-turbo",
            "instructions": null,
            "tools": [{"type": "file_search"}, {"type": "code_interpreter"}],
            "metadata": {},
            "incomplete_details": null,
            "usage": {
              "prompt_tokens": 123,
              "completion_tokens": 456,
              "total_tokens": 579
            },
            "temperature": 1.0,
            "top_p": 1.0,
            "max_prompt_tokens": 1000,
            "max_completion_tokens": 1000,
            "truncation_strategy": {
              "type": "auto",
              "last_messages": null
            },
            "response_format": "auto",
            "tool_choice": "auto"
          }
    CreateRunRequest:
      additionalProperties: false
      properties:
        assistant_id:
          description: "The ID of the [assistant](/docs/api-reference/assistants)\
            \ to use to execute this run."
          type: string
        model:
          $ref: "#/components/schemas/CreateRunRequest_model"
        instructions:
          description: "Overrides the [instructions](/docs/api-reference/assistants/createAssistant)\
            \ of the assistant. This is useful for modifying the behavior on a per-run\
            \ basis."
          nullable: true
          type: string
        additional_instructions:
          description: Appends additional instructions at the end of the instructions
            for the run. This is useful for modifying the behavior on a per-run basis
            without overriding other instructions.
          nullable: true
          type: string
        additional_messages:
          description: Adds additional messages to the thread before creating the
            run.
          items:
            $ref: "#/components/schemas/CreateMessageRequest"
          nullable: true
          type: array
        tools:
          description: Override the tools the assistant can use for this run. This
            is useful for modifying the behavior on a per-run basis.
          items:
            $ref: "#/components/schemas/AssistantObject_tools_inner"
          maxItems: 20
          nullable: true
          type: array
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
        temperature:
          default: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
          example: 1
          maximum: 2
          minimum: 0
          nullable: true
          type: number
        top_p:
          default: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both.
          example: 1
          maximum: 1
          minimum: 0
          nullable: true
          type: number
        stream:
          description: |
            If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.
          nullable: true
          type: boolean
        max_prompt_tokens:
          description: |
            The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.
          minimum: 256
          nullable: true
          type: integer
        max_completion_tokens:
          description: |
            The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.
          minimum: 256
          nullable: true
          type: integer
        truncation_strategy:
          $ref: "#/components/schemas/TruncationObject"
        tool_choice:
          $ref: "#/components/schemas/AssistantsApiToolChoiceOption"
        response_format:
          $ref: "#/components/schemas/AssistantsApiResponseFormatOption"
      required:
      - assistant_id
      - thread_id
      type: object
    ListRunsResponse:
      properties:
        object:
          example: list
          type: string
        data:
          items:
            $ref: "#/components/schemas/RunObject"
          type: array
        first_id:
          example: run_abc123
          type: string
        last_id:
          example: run_abc456
          type: string
        has_more:
          example: false
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
      type: object
    ModifyRunRequest:
      additionalProperties: false
      properties:
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
      type: object
    SubmitToolOutputsRunRequest:
      additionalProperties: false
      properties:
        tool_outputs:
          description: A list of tools for which the outputs are being submitted.
          items:
            $ref: "#/components/schemas/SubmitToolOutputsRunRequest_tool_outputs_inner"
          type: array
        stream:
          description: |
            If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.
          nullable: true
          type: boolean
      required:
      - tool_outputs
      type: object
    RunToolCallObject:
      description: Tool call objects
      properties:
        id:
          description: "The ID of the tool call. This ID must be referenced when you\
            \ submit the tool outputs in using the [Submit tool outputs to run](/docs/api-reference/runs/submitToolOutputs)\
            \ endpoint."
          type: string
        type:
          description: "The type of tool call the output is required for. For now,\
            \ this is always `function`."
          enum:
          - function
          type: string
        function:
          $ref: "#/components/schemas/RunToolCallObject_function"
      required:
      - function
      - id
      - type
      type: object
    CreateThreadAndRunRequest:
      additionalProperties: false
      properties:
        assistant_id:
          description: "The ID of the [assistant](/docs/api-reference/assistants)\
            \ to use to execute this run."
          type: string
        thread:
          $ref: "#/components/schemas/CreateThreadRequest"
        model:
          $ref: "#/components/schemas/CreateRunRequest_model"
        instructions:
          description: Override the default system message of the assistant. This
            is useful for modifying the behavior on a per-run basis.
          nullable: true
          type: string
        tools:
          description: Override the tools the assistant can use for this run. This
            is useful for modifying the behavior on a per-run basis.
          items:
            $ref: "#/components/schemas/CreateThreadAndRunRequest_tools_inner"
          maxItems: 20
          nullable: true
          type: array
        tool_resources:
          $ref: "#/components/schemas/CreateThreadAndRunRequest_tool_resources"
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
        temperature:
          default: 1
          description: |
            What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
          example: 1
          maximum: 2
          minimum: 0
          nullable: true
          type: number
        top_p:
          default: 1
          description: |
            An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

            We generally recommend altering this or temperature but not both.
          example: 1
          maximum: 1
          minimum: 0
          nullable: true
          type: number
        stream:
          description: |
            If `true`, returns a stream of events that happen during the Run as server-sent events, terminating when the Run enters a terminal state with a `data: [DONE]` message.
          nullable: true
          type: boolean
        max_prompt_tokens:
          description: |
            The maximum number of prompt tokens that may be used over the course of the run. The run will make a best effort to use only the number of prompt tokens specified, across multiple turns of the run. If the run exceeds the number of prompt tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.
          minimum: 256
          nullable: true
          type: integer
        max_completion_tokens:
          description: |
            The maximum number of completion tokens that may be used over the course of the run. The run will make a best effort to use only the number of completion tokens specified, across multiple turns of the run. If the run exceeds the number of completion tokens specified, the run will end with status `incomplete`. See `incomplete_details` for more info.
          minimum: 256
          nullable: true
          type: integer
        truncation_strategy:
          $ref: "#/components/schemas/TruncationObject"
        tool_choice:
          $ref: "#/components/schemas/AssistantsApiToolChoiceOption"
        response_format:
          $ref: "#/components/schemas/AssistantsApiResponseFormatOption"
      required:
      - assistant_id
      - thread_id
      type: object
    ThreadObject:
      description: "Represents a thread that contains [messages](/docs/api-reference/messages)."
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints."
          type: string
        object:
          description: "The object type, which is always `thread`."
          enum:
          - thread
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the thread was created.
          type: integer
        tool_resources:
          $ref: "#/components/schemas/ThreadObject_tool_resources"
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
      required:
      - created_at
      - id
      - metadata
      - object
      - tool_resources
      title: Thread
      type: object
      x-oaiMeta:
        name: The thread object
        beta: true
        example: |
          {
            "id": "thread_abc123",
            "object": "thread",
            "created_at": 1698107661,
            "metadata": {}
          }
    CreateThreadRequest:
      additionalProperties: false
      properties:
        messages:
          description: "A list of [messages](/docs/api-reference/messages) to start\
            \ the thread with."
          items:
            $ref: "#/components/schemas/CreateMessageRequest"
          type: array
        tool_resources:
          $ref: "#/components/schemas/CreateThreadRequest_tool_resources"
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
      type: object
    ModifyThreadRequest:
      additionalProperties: false
      properties:
        tool_resources:
          $ref: "#/components/schemas/ThreadObject_tool_resources"
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
      type: object
    DeleteThreadResponse:
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          enum:
          - thread.deleted
          type: string
      required:
      - deleted
      - id
      - object
      type: object
    ListThreadsResponse:
      properties:
        object:
          example: list
          type: string
        data:
          items:
            $ref: "#/components/schemas/ThreadObject"
          type: array
        first_id:
          example: asst_abc123
          type: string
        last_id:
          example: asst_abc456
          type: string
        has_more:
          example: false
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    MessageObject:
      description: "Represents a message within a [thread](/docs/api-reference/threads)."
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints."
          type: string
        object:
          description: "The object type, which is always `thread.message`."
          enum:
          - thread.message
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the message was created.
          type: integer
        thread_id:
          description: "The [thread](/docs/api-reference/threads) ID that this message\
            \ belongs to."
          type: string
        status:
          description: "The status of the message, which can be either `in_progress`,\
            \ `incomplete`, or `completed`."
          enum:
          - in_progress
          - incomplete
          - completed
          type: string
        incomplete_details:
          $ref: "#/components/schemas/MessageObject_incomplete_details"
        completed_at:
          description: The Unix timestamp (in seconds) for when the message was completed.
          nullable: true
          type: integer
        incomplete_at:
          description: The Unix timestamp (in seconds) for when the message was marked
            as incomplete.
          nullable: true
          type: integer
        role:
          description: The entity that produced the message. One of `user` or `assistant`.
          enum:
          - user
          - assistant
          type: string
        content:
          description: The content of the message in array of text and/or images.
          items:
            $ref: "#/components/schemas/MessageObject_content_inner"
          type: array
        assistant_id:
          description: "If applicable, the ID of the [assistant](/docs/api-reference/assistants)\
            \ that authored this message."
          nullable: true
          type: string
        run_id:
          description: "The ID of the [run](/docs/api-reference/runs) associated with\
            \ the creation of this message. Value is `null` when messages are created\
            \ manually using the create message or create thread endpoints."
          nullable: true
          type: string
        attachments:
          description: "A list of files attached to the message, and the tools they\
            \ were added to."
          items:
            $ref: "#/components/schemas/MessageObject_attachments_inner"
          nullable: true
          type: array
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
      required:
      - assistant_id
      - attachments
      - completed_at
      - content
      - created_at
      - id
      - incomplete_at
      - incomplete_details
      - metadata
      - object
      - role
      - run_id
      - status
      - thread_id
      title: The message object
      type: object
      x-oaiMeta:
        name: The message object
        beta: true
        example: |
          {
            "id": "msg_abc123",
            "object": "thread.message",
            "created_at": 1698983503,
            "thread_id": "thread_abc123",
            "role": "assistant",
            "content": [
              {
                "type": "text",
                "text": {
                  "value": "Hi! How can I help you today?",
                  "annotations": []
                }
              }
            ],
            "assistant_id": "asst_abc123",
            "run_id": "run_abc123",
            "attachments": [],
            "metadata": {}
          }
    MessageDeltaObject:
      description: |
        Represents a message delta i.e. any changed fields on a message during streaming.
      properties:
        id:
          description: "The identifier of the message, which can be referenced in\
            \ API endpoints."
          type: string
        object:
          description: "The object type, which is always `thread.message.delta`."
          enum:
          - thread.message.delta
          type: string
        delta:
          $ref: "#/components/schemas/MessageDeltaObject_delta"
      required:
      - delta
      - id
      - object
      title: Message delta object
      type: object
      x-oaiMeta:
        name: The message delta object
        beta: true
        example: |
          {
            "id": "msg_123",
            "object": "thread.message.delta",
            "delta": {
              "content": [
                {
                  "index": 0,
                  "type": "text",
                  "text": { "value": "Hello", "annotations": [] }
                }
              ]
            }
          }
    CreateMessageRequest:
      additionalProperties: false
      properties:
        role:
          description: |
            The role of the entity that is creating the message. Allowed values include:
            - `user`: Indicates the message is sent by an actual user and should be used in most cases to represent user-generated messages.
            - `assistant`: Indicates the message is generated by the assistant. Use this value to insert messages from the assistant into the conversation.
          enum:
          - user
          - assistant
          type: string
        content:
          $ref: "#/components/schemas/CreateMessageRequest_content"
        attachments:
          description: "A list of files attached to the message, and the tools they\
            \ should be added to."
          items:
            $ref: "#/components/schemas/MessageObject_attachments_inner"
          nullable: true
          required:
          - file_id
          - tools
          type: array
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
      required:
      - content
      - role
      type: object
    ModifyMessageRequest:
      additionalProperties: false
      properties:
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
      type: object
    DeleteMessageResponse:
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          enum:
          - thread.message.deleted
          type: string
      required:
      - deleted
      - id
      - object
      type: object
    ListMessagesResponse:
      properties:
        object:
          example: list
          type: string
        data:
          items:
            $ref: "#/components/schemas/MessageObject"
          type: array
        first_id:
          example: msg_abc123
          type: string
        last_id:
          example: msg_abc123
          type: string
        has_more:
          example: false
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    MessageContentImageFileObject:
      description: "References an image [File](/docs/api-reference/files) in the content\
        \ of a message."
      properties:
        type:
          description: Always `image_file`.
          enum:
          - image_file
          type: string
        image_file:
          $ref: "#/components/schemas/MessageContentImageFileObject_image_file"
      required:
      - image_file
      - type
      title: Image file
      type: object
    MessageDeltaContentImageFileObject:
      description: "References an image [File](/docs/api-reference/files) in the content\
        \ of a message."
      properties:
        index:
          description: The index of the content part in the message.
          type: integer
        type:
          description: Always `image_file`.
          enum:
          - image_file
          type: string
        image_file:
          $ref: "#/components/schemas/MessageDeltaContentImageFileObject_image_file"
      required:
      - index
      - type
      title: Image file
      type: object
    MessageContentImageUrlObject:
      description: References an image URL in the content of a message.
      properties:
        type:
          description: The type of the content part.
          enum:
          - image_url
          type: string
        image_url:
          $ref: "#/components/schemas/MessageContentImageUrlObject_image_url"
      required:
      - image_url
      - type
      title: Image URL
      type: object
    MessageDeltaContentImageUrlObject:
      description: References an image URL in the content of a message.
      properties:
        index:
          description: The index of the content part in the message.
          type: integer
        type:
          description: Always `image_url`.
          enum:
          - image_url
          type: string
        image_url:
          $ref: "#/components/schemas/MessageDeltaContentImageUrlObject_image_url"
      required:
      - index
      - type
      title: Image URL
      type: object
    MessageContentTextObject:
      description: The text content that is part of a message.
      properties:
        type:
          description: Always `text`.
          enum:
          - text
          type: string
        text:
          $ref: "#/components/schemas/MessageContentTextObject_text"
      required:
      - text
      - type
      title: Text
      type: object
    MessageRequestContentTextObject:
      description: The text content that is part of a message.
      properties:
        type:
          description: Always `text`.
          enum:
          - text
          type: string
        text:
          description: Text content to be sent to the model
          type: string
      required:
      - text
      - type
      title: Text
      type: object
    MessageContentTextAnnotationsFileCitationObject:
      description: A citation within the message that points to a specific quote from
        a specific File associated with the assistant or the message. Generated when
        the assistant uses the "file_search" tool to search files.
      properties:
        type:
          description: Always `file_citation`.
          enum:
          - file_citation
          type: string
        text:
          description: The text in the message content that needs to be replaced.
          type: string
        file_citation:
          $ref: "#/components/schemas/MessageContentTextAnnotationsFileCitationObject_file_citation"
        start_index:
          minimum: 0
          type: integer
        end_index:
          minimum: 0
          type: integer
      required:
      - end_index
      - file_citation
      - start_index
      - text
      - type
      title: File citation
      type: object
    MessageContentTextAnnotationsFilePathObject:
      description: A URL for the file that's generated when the assistant used the
        `code_interpreter` tool to generate a file.
      properties:
        type:
          description: Always `file_path`.
          enum:
          - file_path
          type: string
        text:
          description: The text in the message content that needs to be replaced.
          type: string
        file_path:
          $ref: "#/components/schemas/MessageContentTextAnnotationsFilePathObject_file_path"
        start_index:
          minimum: 0
          type: integer
        end_index:
          minimum: 0
          type: integer
      required:
      - end_index
      - file_path
      - start_index
      - text
      - type
      title: File path
      type: object
    MessageDeltaContentTextObject:
      description: The text content that is part of a message.
      properties:
        index:
          description: The index of the content part in the message.
          type: integer
        type:
          description: Always `text`.
          enum:
          - text
          type: string
        text:
          $ref: "#/components/schemas/MessageDeltaContentTextObject_text"
      required:
      - index
      - type
      title: Text
      type: object
    MessageDeltaContentTextAnnotationsFileCitationObject:
      description: A citation within the message that points to a specific quote from
        a specific File associated with the assistant or the message. Generated when
        the assistant uses the "file_search" tool to search files.
      properties:
        index:
          description: The index of the annotation in the text content part.
          type: integer
        type:
          description: Always `file_citation`.
          enum:
          - file_citation
          type: string
        text:
          description: The text in the message content that needs to be replaced.
          type: string
        file_citation:
          $ref: "#/components/schemas/MessageDeltaContentTextAnnotationsFileCitationObject_file_citation"
        start_index:
          minimum: 0
          type: integer
        end_index:
          minimum: 0
          type: integer
      required:
      - index
      - type
      title: File citation
      type: object
    MessageDeltaContentTextAnnotationsFilePathObject:
      description: A URL for the file that's generated when the assistant used the
        `code_interpreter` tool to generate a file.
      properties:
        index:
          description: The index of the annotation in the text content part.
          type: integer
        type:
          description: Always `file_path`.
          enum:
          - file_path
          type: string
        text:
          description: The text in the message content that needs to be replaced.
          type: string
        file_path:
          $ref: "#/components/schemas/MessageDeltaContentTextAnnotationsFilePathObject_file_path"
        start_index:
          minimum: 0
          type: integer
        end_index:
          minimum: 0
          type: integer
      required:
      - index
      - type
      title: File path
      type: object
    RunStepObject:
      description: |
        Represents a step in execution of a run.
      properties:
        id:
          description: "The identifier of the run step, which can be referenced in\
            \ API endpoints."
          type: string
        object:
          description: "The object type, which is always `thread.run.step`."
          enum:
          - thread.run.step
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the run step was created.
          type: integer
        assistant_id:
          description: "The ID of the [assistant](/docs/api-reference/assistants)\
            \ associated with the run step."
          type: string
        thread_id:
          description: "The ID of the [thread](/docs/api-reference/threads) that was\
            \ run."
          type: string
        run_id:
          description: "The ID of the [run](/docs/api-reference/runs) that this run\
            \ step is a part of."
          type: string
        type:
          description: "The type of run step, which can be either `message_creation`\
            \ or `tool_calls`."
          enum:
          - message_creation
          - tool_calls
          type: string
        status:
          description: "The status of the run step, which can be either `in_progress`,\
            \ `cancelled`, `failed`, `completed`, or `expired`."
          enum:
          - in_progress
          - cancelled
          - failed
          - completed
          - expired
          type: string
        step_details:
          $ref: "#/components/schemas/RunStepObject_step_details"
        last_error:
          $ref: "#/components/schemas/RunStepObject_last_error"
        expired_at:
          description: The Unix timestamp (in seconds) for when the run step expired.
            A step is considered expired if the parent run is expired.
          nullable: true
          type: integer
        cancelled_at:
          description: The Unix timestamp (in seconds) for when the run step was cancelled.
          nullable: true
          type: integer
        failed_at:
          description: The Unix timestamp (in seconds) for when the run step failed.
          nullable: true
          type: integer
        completed_at:
          description: The Unix timestamp (in seconds) for when the run step completed.
          nullable: true
          type: integer
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
        usage:
          $ref: "#/components/schemas/RunStepCompletionUsage"
      required:
      - assistant_id
      - cancelled_at
      - completed_at
      - created_at
      - expired_at
      - failed_at
      - id
      - last_error
      - metadata
      - object
      - run_id
      - status
      - step_details
      - thread_id
      - type
      - usage
      title: Run steps
      type: object
      x-oaiMeta:
        name: The run step object
        beta: true
        example: |
          {
            "id": "step_abc123",
            "object": "thread.run.step",
            "created_at": 1699063291,
            "run_id": "run_abc123",
            "assistant_id": "asst_abc123",
            "thread_id": "thread_abc123",
            "type": "message_creation",
            "status": "completed",
            "cancelled_at": null,
            "completed_at": 1699063291,
            "expired_at": null,
            "failed_at": null,
            "last_error": null,
            "step_details": {
              "type": "message_creation",
              "message_creation": {
                "message_id": "msg_abc123"
              }
            },
            "usage": {
              "prompt_tokens": 123,
              "completion_tokens": 456,
              "total_tokens": 579
            }
          }
    RunStepDeltaObject:
      description: |
        Represents a run step delta i.e. any changed fields on a run step during streaming.
      properties:
        id:
          description: "The identifier of the run step, which can be referenced in\
            \ API endpoints."
          type: string
        object:
          description: "The object type, which is always `thread.run.step.delta`."
          enum:
          - thread.run.step.delta
          type: string
        delta:
          $ref: "#/components/schemas/RunStepDeltaObject_delta"
      required:
      - delta
      - id
      - object
      title: Run step delta object
      type: object
      x-oaiMeta:
        name: The run step delta object
        beta: true
        example: |
          {
            "id": "step_123",
            "object": "thread.run.step.delta",
            "delta": {
              "step_details": {
                "type": "tool_calls",
                "tool_calls": [
                  {
                    "index": 0,
                    "id": "call_123",
                    "type": "code_interpreter",
                    "code_interpreter": { "input": "", "outputs": [] }
                  }
                ]
              }
            }
          }
    ListRunStepsResponse:
      properties:
        object:
          example: list
          type: string
        data:
          items:
            $ref: "#/components/schemas/RunStepObject"
          type: array
        first_id:
          example: step_abc123
          type: string
        last_id:
          example: step_abc456
          type: string
        has_more:
          example: false
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    RunStepDetailsMessageCreationObject:
      description: Details of the message creation by the run step.
      properties:
        type:
          description: Always `message_creation`.
          enum:
          - message_creation
          type: string
        message_creation:
          $ref: "#/components/schemas/RunStepDetailsMessageCreationObject_message_creation"
      required:
      - message_creation
      - type
      title: Message creation
      type: object
    RunStepDeltaStepDetailsMessageCreationObject:
      description: Details of the message creation by the run step.
      properties:
        type:
          description: Always `message_creation`.
          enum:
          - message_creation
          type: string
        message_creation:
          $ref: "#/components/schemas/RunStepDeltaStepDetailsMessageCreationObject_message_creation"
      required:
      - type
      title: Message creation
      type: object
    RunStepDetailsToolCallsObject:
      description: Details of the tool call.
      properties:
        type:
          description: Always `tool_calls`.
          enum:
          - tool_calls
          type: string
        tool_calls:
          description: |
            An array of tool calls the run step was involved in. These can be associated with one of three types of tools: `code_interpreter`, `file_search`, or `function`.
          items:
            $ref: "#/components/schemas/RunStepDetailsToolCallsObject_tool_calls_inner"
          type: array
      required:
      - tool_calls
      - type
      title: Tool calls
      type: object
    RunStepDeltaStepDetailsToolCallsObject:
      description: Details of the tool call.
      properties:
        type:
          description: Always `tool_calls`.
          enum:
          - tool_calls
          type: string
        tool_calls:
          description: |
            An array of tool calls the run step was involved in. These can be associated with one of three types of tools: `code_interpreter`, `file_search`, or `function`.
          items:
            $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsObject_tool_calls_inner"
          type: array
      required:
      - type
      title: Tool calls
      type: object
    RunStepDetailsToolCallsCodeObject:
      description: Details of the Code Interpreter tool call the run step was involved
        in.
      properties:
        id:
          description: The ID of the tool call.
          type: string
        type:
          description: The type of tool call. This is always going to be `code_interpreter`
            for this type of tool call.
          enum:
          - code_interpreter
          type: string
        code_interpreter:
          $ref: "#/components/schemas/RunStepDetailsToolCallsCodeObject_code_interpreter"
      required:
      - code_interpreter
      - id
      - type
      title: Code Interpreter tool call
      type: object
    RunStepDeltaStepDetailsToolCallsCodeObject:
      description: Details of the Code Interpreter tool call the run step was involved
        in.
      properties:
        index:
          description: The index of the tool call in the tool calls array.
          type: integer
        id:
          description: The ID of the tool call.
          type: string
        type:
          description: The type of tool call. This is always going to be `code_interpreter`
            for this type of tool call.
          enum:
          - code_interpreter
          type: string
        code_interpreter:
          $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeObject_code_interpreter"
      required:
      - index
      - type
      title: Code interpreter tool call
      type: object
    RunStepDetailsToolCallsCodeOutputLogsObject:
      description: Text output from the Code Interpreter tool call as part of a run
        step.
      properties:
        type:
          description: Always `logs`.
          enum:
          - logs
          type: string
        logs:
          description: The text output from the Code Interpreter tool call.
          type: string
      required:
      - logs
      - type
      title: Code Interpreter log output
      type: object
    RunStepDeltaStepDetailsToolCallsCodeOutputLogsObject:
      description: Text output from the Code Interpreter tool call as part of a run
        step.
      properties:
        index:
          description: The index of the output in the outputs array.
          type: integer
        type:
          description: Always `logs`.
          enum:
          - logs
          type: string
        logs:
          description: The text output from the Code Interpreter tool call.
          type: string
      required:
      - index
      - type
      title: Code interpreter log output
      type: object
    RunStepDetailsToolCallsCodeOutputImageObject:
      properties:
        type:
          description: Always `image`.
          enum:
          - image
          type: string
        image:
          $ref: "#/components/schemas/RunStepDetailsToolCallsCodeOutputImageObject_image"
      required:
      - image
      - type
      title: Code Interpreter image output
      type: object
    RunStepDeltaStepDetailsToolCallsCodeOutputImageObject:
      properties:
        index:
          description: The index of the output in the outputs array.
          type: integer
        type:
          description: Always `image`.
          enum:
          - image
          type: string
        image:
          $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputImageObject_image"
      required:
      - index
      - type
      title: Code interpreter image output
      type: object
    RunStepDetailsToolCallsFileSearchObject:
      properties:
        id:
          description: The ID of the tool call object.
          type: string
        type:
          description: The type of tool call. This is always going to be `file_search`
            for this type of tool call.
          enum:
          - file_search
          type: string
        file_search:
          description: "For now, this is always going to be an empty object."
          type: object
          x-oaiTypeLabel: map
      required:
      - file_search
      - id
      - type
      title: File search tool call
      type: object
    RunStepDeltaStepDetailsToolCallsFileSearchObject:
      properties:
        index:
          description: The index of the tool call in the tool calls array.
          type: integer
        id:
          description: The ID of the tool call object.
          type: string
        type:
          description: The type of tool call. This is always going to be `file_search`
            for this type of tool call.
          enum:
          - file_search
          type: string
        file_search:
          description: "For now, this is always going to be an empty object."
          type: object
          x-oaiTypeLabel: map
      required:
      - file_search
      - index
      - type
      title: File search tool call
      type: object
    RunStepDetailsToolCallsFunctionObject:
      properties:
        id:
          description: The ID of the tool call object.
          type: string
        type:
          description: The type of tool call. This is always going to be `function`
            for this type of tool call.
          enum:
          - function
          type: string
        function:
          $ref: "#/components/schemas/RunStepDetailsToolCallsFunctionObject_function"
      required:
      - function
      - id
      - type
      title: Function tool call
      type: object
    RunStepDeltaStepDetailsToolCallsFunctionObject:
      properties:
        index:
          description: The index of the tool call in the tool calls array.
          type: integer
        id:
          description: The ID of the tool call object.
          type: string
        type:
          description: The type of tool call. This is always going to be `function`
            for this type of tool call.
          enum:
          - function
          type: string
        function:
          $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsFunctionObject_function"
      required:
      - index
      - type
      title: Function tool call
      type: object
    VectorStoreExpirationAfter:
      description: The expiration policy for a vector store.
      properties:
        anchor:
          description: "Anchor timestamp after which the expiration policy applies.\
            \ Supported anchors: `last_active_at`."
          enum:
          - last_active_at
          type: string
        days:
          description: The number of days after the anchor time that the vector store
            will expire.
          maximum: 365
          minimum: 1
          type: integer
      required:
      - anchor
      - days
      title: Vector store expiration policy
      type: object
    VectorStoreObject:
      description: A vector store is a collection of processed files can be used by
        the `file_search` tool.
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints."
          type: string
        object:
          description: "The object type, which is always `vector_store`."
          enum:
          - vector_store
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the vector store was
            created.
          type: integer
        name:
          description: The name of the vector store.
          type: string
        usage_bytes:
          description: The total number of bytes used by the files in the vector store.
          type: integer
        file_counts:
          $ref: "#/components/schemas/VectorStoreObject_file_counts"
        status:
          description: "The status of the vector store, which can be either `expired`,\
            \ `in_progress`, or `completed`. A status of `completed` indicates that\
            \ the vector store is ready for use."
          enum:
          - expired
          - in_progress
          - completed
          type: string
        expires_after:
          $ref: "#/components/schemas/VectorStoreExpirationAfter"
        expires_at:
          description: The Unix timestamp (in seconds) for when the vector store will
            expire.
          nullable: true
          type: integer
        last_active_at:
          description: The Unix timestamp (in seconds) for when the vector store was
            last active.
          nullable: true
          type: integer
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
      required:
      - created_at
      - file_counts
      - id
      - last_active_at
      - metadata
      - name
      - object
      - status
      - usage_bytes
      title: Vector store
      type: object
      x-oaiMeta:
        name: The vector store object
        beta: true
        example: |
          {
            "id": "vs_123",
            "object": "vector_store",
            "created_at": 1698107661,
            "usage_bytes": 123456,
            "last_active_at": 1698107661,
            "name": "my_vector_store",
            "status": "completed",
            "file_counts": {
              "in_progress": 0,
              "completed": 100,
              "cancelled": 0,
              "failed": 0,
              "total": 100
            },
            "metadata": {},
            "last_used_at": 1698107661
          }
    CreateVectorStoreRequest:
      additionalProperties: false
      properties:
        file_ids:
          description: "A list of [File](/docs/api-reference/files) IDs that the vector\
            \ store should use. Useful for tools like `file_search` that can access\
            \ files."
          items:
            type: string
          maxItems: 500
          type: array
        name:
          description: The name of the vector store.
          type: string
        expires_after:
          $ref: "#/components/schemas/VectorStoreExpirationAfter"
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
      type: object
    UpdateVectorStoreRequest:
      additionalProperties: false
      properties:
        name:
          description: The name of the vector store.
          nullable: true
          type: string
        expires_after:
          $ref: "#/components/schemas/VectorStoreExpirationAfter"
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
      type: object
    ListVectorStoresResponse:
      properties:
        object:
          example: list
          type: string
        data:
          items:
            $ref: "#/components/schemas/VectorStoreObject"
          type: array
        first_id:
          example: vs_abc123
          type: string
        last_id:
          example: vs_abc456
          type: string
        has_more:
          example: false
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    DeleteVectorStoreResponse:
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          enum:
          - vector_store.deleted
          type: string
      required:
      - deleted
      - id
      - object
      type: object
    VectorStoreFileObject:
      description: A list of files attached to a vector store.
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints."
          type: string
        object:
          description: "The object type, which is always `vector_store.file`."
          enum:
          - vector_store.file
          type: string
        usage_bytes:
          description: The total vector store usage in bytes. Note that this may be
            different from the original file size.
          type: integer
        created_at:
          description: The Unix timestamp (in seconds) for when the vector store file
            was created.
          type: integer
        vector_store_id:
          description: "The ID of the [vector store](/docs/api-reference/vector-stores/object)\
            \ that the [File](/docs/api-reference/files) is attached to."
          type: string
        status:
          description: "The status of the vector store file, which can be either `in_progress`,\
            \ `completed`, `cancelled`, or `failed`. The status `completed` indicates\
            \ that the vector store file is ready for use."
          enum:
          - in_progress
          - completed
          - cancelled
          - failed
          type: string
        last_error:
          $ref: "#/components/schemas/VectorStoreFileObject_last_error"
      required:
      - created_at
      - id
      - last_error
      - object
      - status
      - usage_bytes
      - vector_store_id
      title: Vector store files
      type: object
      x-oaiMeta:
        name: The vector store file object
        beta: true
        example: |
          {
            "id": "file-abc123",
            "object": "vector_store.file",
            "usage_bytes": 1234,
            "created_at": 1698107661,
            "vector_store_id": "vs_abc123",
            "status": "completed",
            "last_error": null
          }
    CreateVectorStoreFileRequest:
      additionalProperties: false
      properties:
        file_id:
          description: "A [File](/docs/api-reference/files) ID that the vector store\
            \ should use. Useful for tools like `file_search` that can access files."
          type: string
      required:
      - file_id
      type: object
    ListVectorStoreFilesResponse:
      properties:
        object:
          example: list
          type: string
        data:
          items:
            $ref: "#/components/schemas/VectorStoreFileObject"
          type: array
        first_id:
          example: file-abc123
          type: string
        last_id:
          example: file-abc456
          type: string
        has_more:
          example: false
          type: boolean
      required:
      - data
      - first_id
      - has_more
      - last_id
      - object
    DeleteVectorStoreFileResponse:
      properties:
        id:
          type: string
        deleted:
          type: boolean
        object:
          enum:
          - vector_store.file.deleted
          type: string
      required:
      - deleted
      - id
      - object
      type: object
    VectorStoreFileBatchObject:
      description: A batch of files attached to a vector store.
      properties:
        id:
          description: "The identifier, which can be referenced in API endpoints."
          type: string
        object:
          description: "The object type, which is always `vector_store.file_batch`."
          enum:
          - vector_store.files_batch
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the vector store files
            batch was created.
          type: integer
        vector_store_id:
          description: "The ID of the [vector store](/docs/api-reference/vector-stores/object)\
            \ that the [File](/docs/api-reference/files) is attached to."
          type: string
        status:
          description: "The status of the vector store files batch, which can be either\
            \ `in_progress`, `completed`, `cancelled` or `failed`."
          enum:
          - in_progress
          - completed
          - cancelled
          - failed
          type: string
        file_counts:
          $ref: "#/components/schemas/VectorStoreFileBatchObject_file_counts"
      required:
      - created_at
      - file_counts
      - id
      - object
      - status
      - vector_store_id
      title: Vector store file batch
      type: object
      x-oaiMeta:
        name: The vector store files batch object
        beta: true
        example: |
          {
            "id": "vsfb_123",
            "object": "vector_store.files_batch",
            "created_at": 1698107661,
            "vector_store_id": "vs_abc123",
            "status": "completed",
            "file_counts": {
              "in_progress": 0,
              "completed": 100,
              "failed": 0,
              "cancelled": 0,
              "total": 100
            }
          }
    CreateVectorStoreFileBatchRequest:
      additionalProperties: false
      properties:
        file_ids:
          description: "A list of [File](/docs/api-reference/files) IDs that the vector\
            \ store should use. Useful for tools like `file_search` that can access\
            \ files."
          items:
            type: string
          maxItems: 500
          minItems: 1
          type: array
      required:
      - file_ids
      type: object
    AssistantStreamEvent:
      description: |
        Represents an event emitted when streaming a Run.

        Each event in a server-sent events stream has an `event` and `data` property:

        ```
        event: thread.created
        data: {"id": "thread_123", "object": "thread", ...}
        ```

        We emit events whenever a new object is created, transitions to a new state, or is being
        streamed in parts (deltas). For example, we emit `thread.run.created` when a new run
        is created, `thread.run.completed` when a run completes, and so on. When an Assistant chooses
        to create a message during a run, we emit a `thread.message.created event`, a
        `thread.message.in_progress` event, many `thread.message.delta` events, and finally a
        `thread.message.completed` event.

        We may add additional events over time, so we recommend handling unknown events gracefully
        in your code. See the [Assistants API quickstart](/docs/assistants/overview) to learn how to
        integrate the Assistants API with streaming.
      oneOf:
      - $ref: "#/components/schemas/ThreadStreamEvent"
      - $ref: "#/components/schemas/RunStreamEvent"
      - $ref: "#/components/schemas/RunStepStreamEvent"
      - $ref: "#/components/schemas/MessageStreamEvent"
      - $ref: "#/components/schemas/ErrorEvent"
      - $ref: "#/components/schemas/DoneEvent"
      x-oaiMeta:
        name: Assistant stream events
        beta: true
    ThreadStreamEvent:
      oneOf:
      - $ref: "#/components/schemas/ThreadStreamEvent_oneOf"
    RunStreamEvent:
      oneOf:
      - $ref: "#/components/schemas/RunStreamEvent_oneOf"
      - $ref: "#/components/schemas/RunStreamEvent_oneOf_1"
      - $ref: "#/components/schemas/RunStreamEvent_oneOf_2"
      - $ref: "#/components/schemas/RunStreamEvent_oneOf_3"
      - $ref: "#/components/schemas/RunStreamEvent_oneOf_4"
      - $ref: "#/components/schemas/RunStreamEvent_oneOf_5"
      - $ref: "#/components/schemas/RunStreamEvent_oneOf_6"
      - $ref: "#/components/schemas/RunStreamEvent_oneOf_7"
      - $ref: "#/components/schemas/RunStreamEvent_oneOf_8"
      - $ref: "#/components/schemas/RunStreamEvent_oneOf_9"
    RunStepStreamEvent:
      oneOf:
      - $ref: "#/components/schemas/RunStepStreamEvent_oneOf"
      - $ref: "#/components/schemas/RunStepStreamEvent_oneOf_1"
      - $ref: "#/components/schemas/RunStepStreamEvent_oneOf_2"
      - $ref: "#/components/schemas/RunStepStreamEvent_oneOf_3"
      - $ref: "#/components/schemas/RunStepStreamEvent_oneOf_4"
      - $ref: "#/components/schemas/RunStepStreamEvent_oneOf_5"
      - $ref: "#/components/schemas/RunStepStreamEvent_oneOf_6"
    MessageStreamEvent:
      oneOf:
      - $ref: "#/components/schemas/MessageStreamEvent_oneOf"
      - $ref: "#/components/schemas/MessageStreamEvent_oneOf_1"
      - $ref: "#/components/schemas/MessageStreamEvent_oneOf_2"
      - $ref: "#/components/schemas/MessageStreamEvent_oneOf_3"
      - $ref: "#/components/schemas/MessageStreamEvent_oneOf_4"
    ErrorEvent:
      description: "Occurs when an [error](/docs/guides/error-codes/api-errors) occurs.\
        \ This can happen due to an internal server error or a timeout."
      properties:
        event:
          enum:
          - error
          type: string
        data:
          $ref: "#/components/schemas/Error"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is an [error](/docs/guides/error-codes/api-errors)"
    DoneEvent:
      description: Occurs when a stream ends.
      properties:
        event:
          enum:
          - done
          type: string
        data:
          enum:
          - "[DONE]"
          type: string
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is `[DONE]`"
    Batch:
      properties:
        id:
          type: string
        object:
          description: "The object type, which is always `batch`."
          enum:
          - batch
          type: string
        endpoint:
          description: The OpenAI API endpoint used by the batch.
          type: string
        errors:
          $ref: "#/components/schemas/Batch_errors"
        input_file_id:
          description: The ID of the input file for the batch.
          type: string
        completion_window:
          description: The time frame within which the batch should be processed.
          type: string
        status:
          description: The current status of the batch.
          enum:
          - validating
          - failed
          - in_progress
          - finalizing
          - completed
          - expired
          - cancelling
          - cancelled
          type: string
        output_file_id:
          description: The ID of the file containing the outputs of successfully executed
            requests.
          type: string
        error_file_id:
          description: The ID of the file containing the outputs of requests with
            errors.
          type: string
        created_at:
          description: The Unix timestamp (in seconds) for when the batch was created.
          type: integer
        in_progress_at:
          description: The Unix timestamp (in seconds) for when the batch started
            processing.
          type: integer
        expires_at:
          description: The Unix timestamp (in seconds) for when the batch will expire.
          type: integer
        finalizing_at:
          description: The Unix timestamp (in seconds) for when the batch started
            finalizing.
          type: integer
        completed_at:
          description: The Unix timestamp (in seconds) for when the batch was completed.
          type: integer
        failed_at:
          description: The Unix timestamp (in seconds) for when the batch failed.
          type: integer
        expired_at:
          description: The Unix timestamp (in seconds) for when the batch expired.
          type: integer
        cancelling_at:
          description: The Unix timestamp (in seconds) for when the batch started
            cancelling.
          type: integer
        cancelled_at:
          description: The Unix timestamp (in seconds) for when the batch was cancelled.
          type: integer
        request_counts:
          $ref: "#/components/schemas/Batch_request_counts"
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to an object. This can be useful for storing additional information about the object in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.
          nullable: true
          type: object
          x-oaiTypeLabel: map
      required:
      - completion_window
      - created_at
      - endpoint
      - id
      - input_file_id
      - object
      - status
      type: object
      x-oaiMeta:
        name: The batch object
        example: |
          {
            "id": "batch_abc123",
            "object": "batch",
            "endpoint": "/v1/completions",
            "errors": null,
            "input_file_id": "file-abc123",
            "completion_window": "24h",
            "status": "completed",
            "output_file_id": "file-cvaTdG",
            "error_file_id": "file-HOWS94",
            "created_at": 1711471533,
            "in_progress_at": 1711471538,
            "expires_at": 1711557933,
            "finalizing_at": 1711493133,
            "completed_at": 1711493163,
            "failed_at": null,
            "expired_at": null,
            "cancelling_at": null,
            "cancelled_at": null,
            "request_counts": {
              "total": 100,
              "completed": 95,
              "failed": 5
            },
            "metadata": {
              "customer_id": "user_123456789",
              "batch_description": "Nightly eval job",
            }
          }
    BatchRequestInput:
      description: The per-line object of the batch input file
      properties:
        custom_id:
          description: A developer-provided per-request id that will be used to match
            outputs to inputs. Must be unique for each request in a batch.
          type: string
        method:
          description: The HTTP method to be used for the request. Currently only
            `POST` is supported.
          enum:
          - POST
          type: string
        url:
          description: "The OpenAI API relative URL to be used for the request. Currently\
            \ `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are\
            \ supported."
          type: string
      type: object
      x-oaiMeta:
        name: The request input object
        example: |
          {"custom_id": "request-1", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-3.5-turbo", "messages": [{"role": "system", "content": "You are a helpful assistant."}, {"role": "user", "content": "What is 2+2?"}]}}
    BatchRequestOutput:
      description: The per-line object of the batch output and error files
      properties:
        id:
          type: string
        custom_id:
          description: A developer-provided per-request id that will be used to match
            outputs to inputs.
          type: string
        response:
          $ref: "#/components/schemas/BatchRequestOutput_response"
        error:
          $ref: "#/components/schemas/BatchRequestOutput_error"
      type: object
      x-oaiMeta:
        name: The request output object
        example: |
          {"id": "batch_req_wnaDys", "custom_id": "request-2", "response": {"status_code": 200, "request_id": "req_c187b3", "body": {"id": "chatcmpl-9758Iw", "object": "chat.completion", "created": 1711475054, "model": "gpt-3.5-turbo", "choices": [{"index": 0, "message": {"role": "assistant", "content": "2 + 2 equals 4."}, "finish_reason": "stop"}], "usage": {"prompt_tokens": 24, "completion_tokens": 15, "total_tokens": 39}, "system_fingerprint": null}}, "error": null}
    ListBatchesResponse:
      properties:
        data:
          items:
            $ref: "#/components/schemas/Batch"
          type: array
        first_id:
          example: batch_abc123
          type: string
        last_id:
          example: batch_abc456
          type: string
        has_more:
          type: boolean
        object:
          enum:
          - list
          type: string
      required:
      - data
      - has_more
      - object
      type: object
    CreateCompletionRequest_model:
      anyOf:
      - type: string
      - enum:
        - gpt-3.5-turbo-instruct
        - davinci-002
        - babbage-002
        type: string
      description: |
        ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them.
      x-oaiTypeLabel: string
    CreateCompletionRequest_prompt:
      default: <|endoftext|>
      description: |
        The prompt(s) to generate completions for, encoded as a string, array of strings, array of tokens, or array of token arrays.

        Note that <|endoftext|> is the document separator that the model sees during training, so if a prompt is not specified the model will generate as if from the beginning of a new document.
      nullable: true
      oneOf:
      - default: ""
        example: This is a test.
        type: string
      - items:
          default: ""
          example: This is a test.
          type: string
        type: array
      - example: "[1212, 318, 257, 1332, 13]"
        items:
          type: integer
        minItems: 1
        type: array
      - example: "[[1212, 318, 257, 1332, 13]]"
        items:
          items:
            type: integer
          minItems: 1
          type: array
        minItems: 1
        type: array
    CreateCompletionRequest_stop:
      default: null
      description: |
        Up to 4 sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence.
      nullable: true
      oneOf:
      - default: <|endoftext|>
        example: |2+

        nullable: true
        type: string
      - items:
          example: "[\"\\n\"]"
          type: string
        maxItems: 4
        minItems: 1
        type: array
    CreateCompletionResponse_choices_inner_logprobs:
      nullable: true
      properties:
        text_offset:
          items:
            type: integer
          type: array
        token_logprobs:
          items:
            type: number
          type: array
        tokens:
          items:
            type: string
          type: array
        top_logprobs:
          items:
            additionalProperties:
              type: number
            type: object
          type: array
      type: object
    CreateCompletionResponse_choices_inner:
      properties:
        finish_reason:
          description: |
            The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
            `length` if the maximum number of tokens specified in the request was reached,
            or `content_filter` if content was omitted due to a flag from our content filters.
          enum:
          - stop
          - length
          - content_filter
          type: string
        index:
          type: integer
        logprobs:
          $ref: "#/components/schemas/CreateCompletionResponse_choices_inner_logprobs"
        text:
          type: string
      required:
      - finish_reason
      - index
      - logprobs
      - text
      type: object
    ChatCompletionRequestMessageContentPartImage_image_url:
      properties:
        url:
          description: Either a URL of the image or the base64 encoded image data.
          format: uri
          type: string
        detail:
          default: auto
          description: "Specifies the detail level of the image. Learn more in the\
            \ [Vision guide](/docs/guides/vision/low-or-high-fidelity-image-understanding)."
          enum:
          - auto
          - low
          - high
          type: string
      required:
      - url
      type: object
    ChatCompletionRequestUserMessage_content:
      description: |
        The contents of the user message.
      oneOf:
      - description: The text contents of the message.
        title: Text content
        type: string
      - description: "An array of content parts with a defined type, each can be of\
          \ type `text` or `image_url` when passing in images. You can pass multiple\
          \ images by adding multiple `image_url` content parts. Image input is only\
          \ supported when using the `gpt-4-visual-preview` model."
        items:
          $ref: "#/components/schemas/ChatCompletionRequestMessageContentPart"
        minItems: 1
        title: Array of content parts
        type: array
      x-oaiExpandable: true
    ChatCompletionRequestAssistantMessage_function_call:
      deprecated: true
      description: "Deprecated and replaced by `tool_calls`. The name and arguments\
        \ of a function that should be called, as generated by the model."
      nullable: true
      properties:
        arguments:
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function."
          type: string
        name:
          description: The name of the function to call.
          type: string
      required:
      - arguments
      - name
      type: object
    ChatCompletionNamedToolChoice_function:
      properties:
        name:
          description: The name of the function to call.
          type: string
      required:
      - name
      type: object
    ChatCompletionMessageToolCall_function:
      description: The function that the model called.
      example:
        name: name
        arguments: arguments
      properties:
        name:
          description: The name of the function to call.
          type: string
        arguments:
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function."
          type: string
      required:
      - arguments
      - name
      type: object
    ChatCompletionMessageToolCallChunk_function:
      properties:
        name:
          description: The name of the function to call.
          type: string
        arguments:
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function."
          type: string
      type: object
    ChatCompletionResponseMessage_function_call:
      deprecated: true
      description: "Deprecated and replaced by `tool_calls`. The name and arguments\
        \ of a function that should be called, as generated by the model."
      example:
        name: name
        arguments: arguments
      properties:
        arguments:
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function."
          type: string
        name:
          description: The name of the function to call.
          type: string
      required:
      - arguments
      - name
      type: object
    ChatCompletionStreamResponseDelta_function_call:
      deprecated: true
      description: "Deprecated and replaced by `tool_calls`. The name and arguments\
        \ of a function that should be called, as generated by the model."
      properties:
        arguments:
          description: "The arguments to call the function with, as generated by the\
            \ model in JSON format. Note that the model does not always generate valid\
            \ JSON, and may hallucinate parameters not defined by your function schema.\
            \ Validate the arguments in your code before calling your function."
          type: string
        name:
          description: The name of the function to call.
          type: string
      type: object
    CreateChatCompletionRequest_model:
      anyOf:
      - type: string
      - enum:
        - gpt-4o
        - gpt-4o-2024-05-13
        - gpt-4-turbo
        - gpt-4-turbo-2024-04-09
        - gpt-4-0125-preview
        - gpt-4-turbo-preview
        - gpt-4-1106-preview
        - gpt-4-vision-preview
        - gpt-4
        - gpt-4-0314
        - gpt-4-0613
        - gpt-4-32k
        - gpt-4-32k-0314
        - gpt-4-32k-0613
        - gpt-3.5-turbo
        - gpt-3.5-turbo-16k
        - gpt-3.5-turbo-0301
        - gpt-3.5-turbo-0613
        - gpt-3.5-turbo-1106
        - gpt-3.5-turbo-0125
        - gpt-3.5-turbo-16k-0613
        type: string
      description: "ID of the model to use. See the [model endpoint compatibility](/docs/models/model-endpoint-compatibility)\
        \ table for details on which models work with the Chat API."
      example: gpt-4-turbo
      x-oaiTypeLabel: string
    CreateChatCompletionRequest_response_format:
      description: |
        An object specifying the format that the model must output. Compatible with [GPT-4 Turbo](/docs/models/gpt-4-and-gpt-4-turbo) and all GPT-3.5 Turbo models newer than `gpt-3.5-turbo-1106`.

        Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees the message the model generates is valid JSON.

        **Important:** when using JSON mode, you **must** also instruct the model to produce JSON yourself via a system or user message. Without this, the model may generate an unending stream of whitespace until the generation reaches the token limit, resulting in a long-running and seemingly "stuck" request. Also note that the message content may be partially cut off if `finish_reason="length"`, which indicates the generation exceeded `max_tokens` or the conversation exceeded the max context length.
      example:
        type: json_object
      properties:
        type:
          default: text
          description: Must be one of `text` or `json_object`.
          enum:
          - text
          - json_object
          example: json_object
          type: string
      type: object
    CreateChatCompletionRequest_stop:
      default: null
      description: |
        Up to 4 sequences where the API will stop generating further tokens.
      oneOf:
      - nullable: true
        type: string
      - items:
          type: string
        maxItems: 4
        minItems: 1
        type: array
    CreateChatCompletionRequest_function_call:
      deprecated: true
      description: |
        Deprecated in favor of `tool_choice`.

        Controls which (if any) function is called by the model.
        `none` means the model will not call a function and instead generates a message.
        `auto` means the model can pick between generating a message or calling a function.
        Specifying a particular function via `{"name": "my_function"}` forces the model to call that function.

        `none` is the default when no functions are present. `auto` is the default if functions are present.
      oneOf:
      - description: |
          `none` means the model will not call a function and instead generates a message. `auto` means the model can pick between generating a message or calling a function.
        enum:
        - none
        - auto
        type: string
      - $ref: "#/components/schemas/ChatCompletionFunctionCallOption"
      x-oaiExpandable: true
    CreateChatCompletionResponse_choices_inner_logprobs:
      description: Log probability information for the choice.
      example:
        content:
        - top_logprobs:
          - logprob: 5.962133916683182
            bytes:
            - 5
            - 5
            token: token
          - logprob: 5.962133916683182
            bytes:
            - 5
            - 5
            token: token
          logprob: 6.027456183070403
          bytes:
          - 1
          - 1
          token: token
        - top_logprobs:
          - logprob: 5.962133916683182
            bytes:
            - 5
            - 5
            token: token
          - logprob: 5.962133916683182
            bytes:
            - 5
            - 5
            token: token
          logprob: 6.027456183070403
          bytes:
          - 1
          - 1
          token: token
      nullable: true
      properties:
        content:
          description: A list of message content tokens with log probability information.
          items:
            $ref: "#/components/schemas/ChatCompletionTokenLogprob"
          nullable: true
          type: array
      required:
      - content
      type: object
    CreateChatCompletionResponse_choices_inner:
      example:
        finish_reason: stop
        index: 0
        message:
          role: assistant
          function_call:
            name: name
            arguments: arguments
          tool_calls:
          - function:
              name: name
              arguments: arguments
            id: id
            type: function
          - function:
              name: name
              arguments: arguments
            id: id
            type: function
          content: content
        logprobs:
          content:
          - top_logprobs:
            - logprob: 5.962133916683182
              bytes:
              - 5
              - 5
              token: token
            - logprob: 5.962133916683182
              bytes:
              - 5
              - 5
              token: token
            logprob: 6.027456183070403
            bytes:
            - 1
            - 1
            token: token
          - top_logprobs:
            - logprob: 5.962133916683182
              bytes:
              - 5
              - 5
              token: token
            - logprob: 5.962133916683182
              bytes:
              - 5
              - 5
              token: token
            logprob: 6.027456183070403
            bytes:
            - 1
            - 1
            token: token
      properties:
        finish_reason:
          description: |
            The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
            `length` if the maximum number of tokens specified in the request was reached,
            `content_filter` if content was omitted due to a flag from our content filters,
            `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
          enum:
          - stop
          - length
          - tool_calls
          - content_filter
          - function_call
          type: string
        index:
          description: The index of the choice in the list of choices.
          type: integer
        message:
          $ref: "#/components/schemas/ChatCompletionResponseMessage"
        logprobs:
          $ref: "#/components/schemas/CreateChatCompletionResponse_choices_inner_logprobs"
      required:
      - finish_reason
      - index
      - logprobs
      - message
      type: object
    CreateChatCompletionFunctionResponse_choices_inner:
      properties:
        finish_reason:
          description: |
            The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence, `length` if the maximum number of tokens specified in the request was reached, `content_filter` if content was omitted due to a flag from our content filters, or `function_call` if the model called a function.
          enum:
          - stop
          - length
          - function_call
          - content_filter
          type: string
        index:
          description: The index of the choice in the list of choices.
          type: integer
        message:
          $ref: "#/components/schemas/ChatCompletionResponseMessage"
      required:
      - finish_reason
      - index
      - logprobs
      - message
      type: object
    ChatCompletionTokenLogprob_top_logprobs_inner:
      example:
        logprob: 5.962133916683182
        bytes:
        - 5
        - 5
        token: token
      properties:
        token:
          description: The token.
          type: string
        logprob:
          description: "The log probability of this token, if it is within the top\
            \ 20 most likely tokens. Otherwise, the value `-9999.0` is used to signify\
            \ that the token is very unlikely."
          type: number
        bytes:
          description: A list of integers representing the UTF-8 bytes representation
            of the token. Useful in instances where characters are represented by
            multiple tokens and their byte representations must be combined to generate
            the correct text representation. Can be `null` if there is no bytes representation
            for the token.
          items:
            type: integer
          nullable: true
          type: array
      required:
      - bytes
      - logprob
      - token
      type: object
    CreateChatCompletionStreamResponse_choices_inner:
      properties:
        delta:
          $ref: "#/components/schemas/ChatCompletionStreamResponseDelta"
        logprobs:
          $ref: "#/components/schemas/CreateChatCompletionResponse_choices_inner_logprobs"
        finish_reason:
          description: |
            The reason the model stopped generating tokens. This will be `stop` if the model hit a natural stop point or a provided stop sequence,
            `length` if the maximum number of tokens specified in the request was reached,
            `content_filter` if content was omitted due to a flag from our content filters,
            `tool_calls` if the model called a tool, or `function_call` (deprecated) if the model called a function.
          enum:
          - stop
          - length
          - tool_calls
          - content_filter
          - function_call
          nullable: true
          type: string
        index:
          description: The index of the choice in the list of choices.
          type: integer
      required:
      - delta
      - finish_reason
      - index
      type: object
    CreateChatCompletionStreamResponse_usage:
      description: |
        An optional field that will only be present when you set `stream_options: {"include_usage": true}` in your request.
        When present, it contains a null value except for the last chunk which contains the token usage statistics for the entire request.
      properties:
        completion_tokens:
          description: Number of tokens in the generated completion.
          type: integer
        prompt_tokens:
          description: Number of tokens in the prompt.
          type: integer
        total_tokens:
          description: Total number of tokens used in the request (prompt + completion).
          type: integer
      required:
      - completion_tokens
      - prompt_tokens
      - total_tokens
      type: object
    CreateImageEditRequest_model:
      anyOf:
      - type: string
      - enum:
        - dall-e-2
        type: string
      default: dall-e-2
      description: The model to use for image generation. Only `dall-e-2` is supported
        at this time.
      example: dall-e-2
      nullable: true
      x-oaiTypeLabel: string
    CreateModerationRequest_input:
      description: The input text to classify
      oneOf:
      - default: ""
        example: I want to kill them.
        type: string
      - items:
          default: ""
          example: I want to kill them.
          type: string
        type: array
    CreateModerationRequest_model:
      anyOf:
      - type: string
      - enum:
        - text-moderation-latest
        - text-moderation-stable
        type: string
      default: text-moderation-latest
      description: |
        Two content moderations models are available: `text-moderation-stable` and `text-moderation-latest`.

        The default is `text-moderation-latest` which will be automatically upgraded over time. This ensures you are always using our most accurate model. If you use `text-moderation-stable`, we will provide advanced notice before updating the model. Accuracy of `text-moderation-stable` may be slightly lower than for `text-moderation-latest`.
      example: text-moderation-stable
      nullable: false
      x-oaiTypeLabel: string
    CreateModerationResponse_results_inner_categories:
      description: "A list of the categories, and whether they are flagged or not."
      properties:
        hate:
          description: "Content that expresses, incites, or promotes hate based on\
            \ race, gender, ethnicity, religion, nationality, sexual orientation,\
            \ disability status, or caste. Hateful content aimed at non-protected\
            \ groups (e.g., chess players) is harassment."
          type: boolean
        hate/threatening:
          description: "Hateful content that also includes violence or serious harm\
            \ towards the targeted group based on race, gender, ethnicity, religion,\
            \ nationality, sexual orientation, disability status, or caste."
          type: boolean
        harassment:
          description: "Content that expresses, incites, or promotes harassing language\
            \ towards any target."
          type: boolean
        harassment/threatening:
          description: Harassment content that also includes violence or serious harm
            towards any target.
          type: boolean
        self-harm:
          description: "Content that promotes, encourages, or depicts acts of self-harm,\
            \ such as suicide, cutting, and eating disorders."
          type: boolean
        self-harm/intent:
          description: "Content where the speaker expresses that they are engaging\
            \ or intend to engage in acts of self-harm, such as suicide, cutting,\
            \ and eating disorders."
          type: boolean
        self-harm/instructions:
          description: "Content that encourages performing acts of self-harm, such\
            \ as suicide, cutting, and eating disorders, or that gives instructions\
            \ or advice on how to commit such acts."
          type: boolean
        sexual:
          description: "Content meant to arouse sexual excitement, such as the description\
            \ of sexual activity, or that promotes sexual services (excluding sex\
            \ education and wellness)."
          type: boolean
        sexual/minors:
          description: Sexual content that includes an individual who is under 18
            years old.
          type: boolean
        violence:
          description: "Content that depicts death, violence, or physical injury."
          type: boolean
        violence/graphic:
          description: "Content that depicts death, violence, or physical injury in\
            \ graphic detail."
          type: boolean
      required:
      - harassment
      - harassment/threatening
      - hate
      - hate/threatening
      - self-harm
      - self-harm/instructions
      - self-harm/intent
      - sexual
      - sexual/minors
      - violence
      - violence/graphic
      type: object
    CreateModerationResponse_results_inner_category_scores:
      description: A list of the categories along with their scores as predicted by
        model.
      properties:
        hate:
          description: The score for the category 'hate'.
          type: number
        hate/threatening:
          description: The score for the category 'hate/threatening'.
          type: number
        harassment:
          description: The score for the category 'harassment'.
          type: number
        harassment/threatening:
          description: The score for the category 'harassment/threatening'.
          type: number
        self-harm:
          description: The score for the category 'self-harm'.
          type: number
        self-harm/intent:
          description: The score for the category 'self-harm/intent'.
          type: number
        self-harm/instructions:
          description: The score for the category 'self-harm/instructions'.
          type: number
        sexual:
          description: The score for the category 'sexual'.
          type: number
        sexual/minors:
          description: The score for the category 'sexual/minors'.
          type: number
        violence:
          description: The score for the category 'violence'.
          type: number
        violence/graphic:
          description: The score for the category 'violence/graphic'.
          type: number
      required:
      - harassment
      - harassment/threatening
      - hate
      - hate/threatening
      - self-harm
      - self-harm/instructions
      - self-harm/intent
      - sexual
      - sexual/minors
      - violence
      - violence/graphic
      type: object
    CreateModerationResponse_results_inner:
      properties:
        flagged:
          description: Whether any of the below categories are flagged.
          type: boolean
        categories:
          $ref: "#/components/schemas/CreateModerationResponse_results_inner_categories"
        category_scores:
          $ref: "#/components/schemas/CreateModerationResponse_results_inner_category_scores"
      required:
      - categories
      - category_scores
      - flagged
      type: object
    CreateFineTuningJobRequest_model:
      anyOf:
      - type: string
      - enum:
        - babbage-002
        - davinci-002
        - gpt-3.5-turbo
        type: string
      description: |
        The name of the model to fine-tune. You can select one of the
        [supported models](/docs/guides/fine-tuning/what-models-can-be-fine-tuned).
      example: gpt-3.5-turbo
      x-oaiTypeLabel: string
    CreateFineTuningJobRequest_hyperparameters_batch_size:
      default: auto
      description: |
        Number of examples in each batch. A larger batch size means that model parameters
        are updated less frequently, but with lower variance.
      oneOf:
      - enum:
        - auto
        type: string
      - maximum: 256
        minimum: 1
        type: integer
    CreateFineTuningJobRequest_hyperparameters_learning_rate_multiplier:
      default: auto
      description: |
        Scaling factor for the learning rate. A smaller learning rate may be useful to avoid
        overfitting.
      oneOf:
      - enum:
        - auto
        type: string
      - exclusiveMinimum: true
        minimum: 0
        type: number
    CreateFineTuningJobRequest_hyperparameters_n_epochs:
      default: auto
      description: |
        The number of epochs to train the model for. An epoch refers to one full cycle
        through the training dataset.
      oneOf:
      - enum:
        - auto
        type: string
      - maximum: 50
        minimum: 1
        type: integer
    CreateFineTuningJobRequest_hyperparameters:
      description: The hyperparameters used for the fine-tuning job.
      properties:
        batch_size:
          $ref: "#/components/schemas/CreateFineTuningJobRequest_hyperparameters_batch_size"
        learning_rate_multiplier:
          $ref: "#/components/schemas/CreateFineTuningJobRequest_hyperparameters_learning_rate_multiplier"
        n_epochs:
          $ref: "#/components/schemas/CreateFineTuningJobRequest_hyperparameters_n_epochs"
      type: object
    CreateFineTuningJobRequest_integrations_inner_type:
      description: |
        The type of integration to enable. Currently, only "wandb" (Weights and Biases) is supported.
      oneOf:
      - enum:
        - wandb
        type: string
    CreateFineTuningJobRequest_integrations_inner_wandb:
      description: |
        The settings for your integration with Weights and Biases. This payload specifies the project that
        metrics will be sent to. Optionally, you can set an explicit display name for your run, add tags
        to your run, and set a default entity (team, username, etc) to be associated with your run.
      properties:
        project:
          description: |
            The name of the project that the new run will be created under.
          example: my-wandb-project
          type: string
        name:
          description: |
            A display name to set for the run. If not set, we will use the Job ID as the name.
          nullable: true
          type: string
        entity:
          description: |
            The entity to use for the run. This allows you to set the team or username of the WandB user that you would
            like associated with the run. If not set, the default entity for the registered WandB API key is used.
          nullable: true
          type: string
        tags:
          description: |
            A list of tags to be attached to the newly created run. These tags are passed through directly to WandB. Some
            default tags are generated by OpenAI: "openai/finetune", "openai/{base-model}", "openai/{ftjob-abcdef}".
          items:
            example: custom-tag
            type: string
          type: array
      required:
      - project
      type: object
    CreateFineTuningJobRequest_integrations_inner:
      properties:
        type:
          $ref: "#/components/schemas/CreateFineTuningJobRequest_integrations_inner_type"
        wandb:
          $ref: "#/components/schemas/CreateFineTuningJobRequest_integrations_inner_wandb"
      required:
      - type
      - wandb
      type: object
    CreateEmbeddingRequest_input:
      description: |
        Input text to embed, encoded as a string or array of tokens. To embed multiple inputs in a single request, pass an array of strings or array of token arrays. The input must not exceed the max input tokens for the model (8192 tokens for `text-embedding-ada-002`), cannot be an empty string, and any array must be 2048 dimensions or less. [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken) for counting tokens.
      example: The quick brown fox jumped over the lazy dog
      oneOf:
      - default: ""
        description: The string that will be turned into an embedding.
        example: This is a test.
        title: string
        type: string
      - description: The array of strings that will be turned into an embedding.
        items:
          default: ""
          example: "['This is a test.']"
          type: string
        maxItems: 2048
        minItems: 1
        title: array
        type: array
      - description: The array of integers that will be turned into an embedding.
        example: "[1212, 318, 257, 1332, 13]"
        items:
          type: integer
        maxItems: 2048
        minItems: 1
        title: array
        type: array
      - description: The array of arrays containing integers that will be turned into
          an embedding.
        example: "[[1212, 318, 257, 1332, 13]]"
        items:
          items:
            type: integer
          minItems: 1
          type: array
        maxItems: 2048
        minItems: 1
        title: array
        type: array
      x-oaiExpandable: true
    CreateEmbeddingRequest_model:
      anyOf:
      - type: string
      - enum:
        - text-embedding-ada-002
        - text-embedding-3-small
        - text-embedding-3-large
        type: string
      description: |
        ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them.
      example: text-embedding-3-small
      x-oaiTypeLabel: string
    CreateEmbeddingResponse_usage:
      description: The usage information for the request.
      example:
        prompt_tokens: 1
        total_tokens: 5
      properties:
        prompt_tokens:
          description: The number of tokens used by the prompt.
          type: integer
        total_tokens:
          description: The total number of tokens used by the request.
          type: integer
      required:
      - prompt_tokens
      - total_tokens
      type: object
    CreateTranscriptionRequest_model:
      anyOf:
      - type: string
      - enum:
        - whisper-1
        type: string
      description: |
        ID of the model to use. Only `whisper-1` (which is powered by our open source Whisper V2 model) is currently available.
      example: whisper-1
      x-oaiTypeLabel: string
    CreateSpeechRequest_model:
      anyOf:
      - type: string
      - enum:
        - tts-1
        - tts-1-hd
        type: string
      description: |
        One of the available [TTS models](/docs/models/tts): `tts-1` or `tts-1-hd`
      x-oaiTypeLabel: string
    FineTuningJob_error:
      description: "For fine-tuning jobs that have `failed`, this will contain more\
        \ information on the cause of the failure."
      nullable: true
      properties:
        code:
          description: A machine-readable error code.
          type: string
        message:
          description: A human-readable error message.
          type: string
        param:
          description: "The parameter that was invalid, usually `training_file` or\
            \ `validation_file`. This field will be null if the failure was not parameter-specific."
          nullable: true
          type: string
      required:
      - code
      - message
      - param
      type: object
    FineTuningJob_hyperparameters_n_epochs:
      default: auto
      description: |-
        The number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.
        "auto" decides the optimal number of epochs based on the size of the dataset. If setting the number manually, we support any number between 1 and 50 epochs.
      oneOf:
      - enum:
        - auto
        type: string
      - maximum: 50
        minimum: 1
        type: integer
    FineTuningJob_hyperparameters:
      description: "The hyperparameters used for the fine-tuning job. See the [fine-tuning\
        \ guide](/docs/guides/fine-tuning) for more details."
      properties:
        n_epochs:
          $ref: "#/components/schemas/FineTuningJob_hyperparameters_n_epochs"
      required:
      - n_epochs
      type: object
    FineTuningJob_integrations_inner:
      oneOf:
      - $ref: "#/components/schemas/FineTuningIntegration"
      x-oaiExpandable: true
    FineTuningJobCheckpoint_metrics:
      description: Metrics at the step number during the fine-tuning job.
      properties:
        step:
          type: number
        train_loss:
          type: number
        train_mean_token_accuracy:
          type: number
        valid_loss:
          type: number
        valid_mean_token_accuracy:
          type: number
        full_valid_loss:
          type: number
        full_valid_mean_token_accuracy:
          type: number
      type: object
    AssistantObject_tools_inner:
      oneOf:
      - $ref: "#/components/schemas/AssistantToolsCode"
      - $ref: "#/components/schemas/AssistantToolsFileSearch"
      - $ref: "#/components/schemas/AssistantToolsFunction"
      x-oaiExpandable: true
    AssistantObject_tool_resources_code_interpreter:
      properties:
        file_ids:
          default: []
          description: |
            A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter`` tool. There can be a maximum of 20 files associated with the tool.
          items:
            type: string
          maxItems: 20
          type: array
      type: object
    AssistantObject_tool_resources_file_search:
      properties:
        vector_store_ids:
          description: |
            The ID of the [vector store](/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.
          items:
            type: string
          maxItems: 1
          type: array
      type: object
    AssistantObject_tool_resources:
      description: |
        A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
      nullable: true
      properties:
        code_interpreter:
          $ref: "#/components/schemas/AssistantObject_tool_resources_code_interpreter"
        file_search:
          $ref: "#/components/schemas/AssistantObject_tool_resources_file_search"
      type: object
    CreateAssistantRequest_model:
      anyOf:
      - type: string
      - enum:
        - gpt-4o
        - gpt-4o-2024-05-13
        - gpt-4-turbo
        - gpt-4-turbo-2024-04-09
        - gpt-4-0125-preview
        - gpt-4-turbo-preview
        - gpt-4-1106-preview
        - gpt-4-vision-preview
        - gpt-4
        - gpt-4-0314
        - gpt-4-0613
        - gpt-4-32k
        - gpt-4-32k-0314
        - gpt-4-32k-0613
        - gpt-3.5-turbo
        - gpt-3.5-turbo-16k
        - gpt-3.5-turbo-0613
        - gpt-3.5-turbo-1106
        - gpt-3.5-turbo-0125
        - gpt-3.5-turbo-16k-0613
        type: string
      description: |
        ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models/overview) for descriptions of them.
      example: gpt-4-turbo
      x-oaiTypeLabel: string
    CreateAssistantRequest_tool_resources_code_interpreter:
      properties:
        file_ids:
          default: []
          description: |
            A list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.
          items:
            type: string
          maxItems: 20
          type: array
      type: object
    CreateAssistantRequest_tool_resources_file_search_vector_stores_inner:
      properties:
        file_ids:
          description: |
            A list of [file](/docs/api-reference/files) IDs to add to the vector store. There can be a maximum of 10000 files in a vector store.
          items:
            type: string
          maxItems: 10000
          type: array
        metadata:
          description: |
            Set of 16 key-value pairs that can be attached to a vector store. This can be useful for storing additional information about the vector store in a structured format. Keys can be a maximum of 64 characters long and values can be a maxium of 512 characters long.
          type: object
          x-oaiTypeLabel: map
      type: object
    CreateAssistantRequest_tool_resources_file_search:
      nullable: true
      oneOf: []
      properties:
        vector_store_ids:
          description: |
            The [vector store](/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.
          items:
            type: string
          maxItems: 1
          type: array
        vector_stores:
          description: |
            A helper to create a [vector store](/docs/api-reference/vector-stores/object) with file_ids and attach it to this assistant. There can be a maximum of 1 vector store attached to the assistant.
          items:
            $ref: "#/components/schemas/CreateAssistantRequest_tool_resources_file_search_vector_stores_inner"
          maxItems: 1
          type: array
      type: object
    CreateAssistantRequest_tool_resources:
      description: |
        A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
      nullable: true
      properties:
        code_interpreter:
          $ref: "#/components/schemas/CreateAssistantRequest_tool_resources_code_interpreter"
        file_search:
          $ref: "#/components/schemas/CreateAssistantRequest_tool_resources_file_search"
      type: object
    ModifyAssistantRequest_tool_resources_code_interpreter:
      properties:
        file_ids:
          default: []
          description: |
            Overrides the list of [file](/docs/api-reference/files) IDs made available to the `code_interpreter` tool. There can be a maximum of 20 files associated with the tool.
          items:
            type: string
          maxItems: 20
          type: array
      type: object
    ModifyAssistantRequest_tool_resources_file_search:
      properties:
        vector_store_ids:
          description: |
            Overrides the [vector store](/docs/api-reference/vector-stores/object) attached to this assistant. There can be a maximum of 1 vector store attached to the assistant.
          items:
            type: string
          maxItems: 1
          type: array
      type: object
    ModifyAssistantRequest_tool_resources:
      description: |
        A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
      nullable: true
      properties:
        code_interpreter:
          $ref: "#/components/schemas/ModifyAssistantRequest_tool_resources_code_interpreter"
        file_search:
          $ref: "#/components/schemas/ModifyAssistantRequest_tool_resources_file_search"
      type: object
    RunObject_required_action_submit_tool_outputs:
      description: Details on the tool outputs needed for this run to continue.
      properties:
        tool_calls:
          description: A list of the relevant tool calls.
          items:
            $ref: "#/components/schemas/RunToolCallObject"
          type: array
      required:
      - tool_calls
      type: object
    RunObject_required_action:
      description: Details on the action required to continue the run. Will be `null`
        if no action is required.
      nullable: true
      properties:
        type:
          description: "For now, this is always `submit_tool_outputs`."
          enum:
          - submit_tool_outputs
          type: string
        submit_tool_outputs:
          $ref: "#/components/schemas/RunObject_required_action_submit_tool_outputs"
      required:
      - submit_tool_outputs
      - type
      type: object
    RunObject_last_error:
      description: The last error associated with this run. Will be `null` if there
        are no errors.
      nullable: true
      properties:
        code:
          description: "One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`."
          enum:
          - server_error
          - rate_limit_exceeded
          - invalid_prompt
          type: string
        message:
          description: A human-readable description of the error.
          type: string
      required:
      - code
      - message
      type: object
    RunObject_incomplete_details:
      description: Details on why the run is incomplete. Will be `null` if the run
        is not incomplete.
      nullable: true
      properties:
        reason:
          description: The reason why the run is incomplete. This will point to which
            specific token limit was reached over the course of the run.
          enum:
          - max_completion_tokens
          - max_prompt_tokens
          type: string
      type: object
    CreateRunRequest_model:
      anyOf:
      - type: string
      - enum:
        - gpt-4o
        - gpt-4o-2024-05-13
        - gpt-4-turbo
        - gpt-4-turbo-2024-04-09
        - gpt-4-0125-preview
        - gpt-4-turbo-preview
        - gpt-4-1106-preview
        - gpt-4-vision-preview
        - gpt-4
        - gpt-4-0314
        - gpt-4-0613
        - gpt-4-32k
        - gpt-4-32k-0314
        - gpt-4-32k-0613
        - gpt-3.5-turbo
        - gpt-3.5-turbo-16k
        - gpt-3.5-turbo-0613
        - gpt-3.5-turbo-1106
        - gpt-3.5-turbo-0125
        - gpt-3.5-turbo-16k-0613
        type: string
      description: "The ID of the [Model](/docs/api-reference/models) to be used to\
        \ execute this run. If a value is provided here, it will override the model\
        \ associated with the assistant. If not, the model associated with the assistant\
        \ will be used."
      example: gpt-4-turbo
      nullable: true
      x-oaiTypeLabel: string
    SubmitToolOutputsRunRequest_tool_outputs_inner:
      properties:
        tool_call_id:
          description: The ID of the tool call in the `required_action` object within
            the run object the output is being submitted for.
          type: string
        output:
          description: The output of the tool call to be submitted to continue the
            run.
          type: string
      type: object
    RunToolCallObject_function:
      description: The function definition.
      properties:
        name:
          description: The name of the function.
          type: string
        arguments:
          description: The arguments that the model expects you to pass to the function.
          type: string
      required:
      - arguments
      - name
      type: object
    CreateThreadAndRunRequest_tools_inner:
      oneOf:
      - $ref: "#/components/schemas/AssistantToolsCode"
      - $ref: "#/components/schemas/AssistantToolsFileSearch"
      - $ref: "#/components/schemas/AssistantToolsFunction"
    CreateThreadAndRunRequest_tool_resources:
      description: |
        A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
      nullable: true
      properties:
        code_interpreter:
          $ref: "#/components/schemas/CreateAssistantRequest_tool_resources_code_interpreter"
        file_search:
          $ref: "#/components/schemas/AssistantObject_tool_resources_file_search"
      type: object
    ThreadObject_tool_resources_file_search:
      properties:
        vector_store_ids:
          description: |
            The [vector store](/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread.
          items:
            type: string
          maxItems: 1
          type: array
      type: object
    ThreadObject_tool_resources:
      description: |
        A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
      nullable: true
      properties:
        code_interpreter:
          $ref: "#/components/schemas/CreateAssistantRequest_tool_resources_code_interpreter"
        file_search:
          $ref: "#/components/schemas/ThreadObject_tool_resources_file_search"
      type: object
    CreateThreadRequest_tool_resources_file_search:
      nullable: true
      oneOf: []
      properties:
        vector_store_ids:
          description: |
            The [vector store](/docs/api-reference/vector-stores/object) attached to this thread. There can be a maximum of 1 vector store attached to the thread.
          items:
            type: string
          maxItems: 1
          type: array
        vector_stores:
          description: |
            A helper to create a [vector store](/docs/api-reference/vector-stores/object) with file_ids and attach it to this thread. There can be a maximum of 1 vector store attached to the thread.
          items:
            $ref: "#/components/schemas/CreateAssistantRequest_tool_resources_file_search_vector_stores_inner"
          maxItems: 1
          type: array
      type: object
    CreateThreadRequest_tool_resources:
      description: |
        A set of resources that are made available to the assistant's tools in this thread. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.
      nullable: true
      properties:
        code_interpreter:
          $ref: "#/components/schemas/CreateAssistantRequest_tool_resources_code_interpreter"
        file_search:
          $ref: "#/components/schemas/CreateThreadRequest_tool_resources_file_search"
      type: object
    MessageObject_incomplete_details:
      description: "On an incomplete message, details about why the message is incomplete."
      nullable: true
      properties:
        reason:
          description: The reason the message is incomplete.
          enum:
          - content_filter
          - max_tokens
          - run_cancelled
          - run_expired
          - run_failed
          type: string
      required:
      - reason
      type: object
    MessageObject_content_inner:
      oneOf:
      - $ref: "#/components/schemas/MessageContentImageFileObject"
      - $ref: "#/components/schemas/MessageContentImageUrlObject"
      - $ref: "#/components/schemas/MessageContentTextObject"
      x-oaiExpandable: true
    MessageObject_attachments_inner_tools_inner:
      oneOf:
      - $ref: "#/components/schemas/AssistantToolsCode"
      - $ref: "#/components/schemas/AssistantToolsFileSearch"
      x-oaiExpandable: true
    MessageObject_attachments_inner:
      properties:
        file_id:
          description: The ID of the file to attach to the message.
          type: string
        tools:
          description: The tools to add this file to.
          items:
            $ref: "#/components/schemas/MessageObject_attachments_inner_tools_inner"
          type: array
      type: object
    MessageDeltaObject_delta_content_inner:
      oneOf:
      - $ref: "#/components/schemas/MessageDeltaContentImageFileObject"
      - $ref: "#/components/schemas/MessageDeltaContentTextObject"
      - $ref: "#/components/schemas/MessageDeltaContentImageUrlObject"
      x-oaiExpandable: true
    MessageDeltaObject_delta:
      description: The delta containing the fields that have changed on the Message.
      properties:
        role:
          description: The entity that produced the message. One of `user` or `assistant`.
          enum:
          - user
          - assistant
          type: string
        content:
          description: The content of the message in array of text and/or images.
          items:
            $ref: "#/components/schemas/MessageDeltaObject_delta_content_inner"
          type: array
      type: object
    Array_of_content_parts_inner:
      oneOf:
      - $ref: "#/components/schemas/MessageContentImageFileObject"
      - $ref: "#/components/schemas/MessageContentImageUrlObject"
      - $ref: "#/components/schemas/MessageRequestContentTextObject"
      x-oaiExpandable: true
    CreateMessageRequest_content:
      oneOf:
      - description: The text contents of the message.
        title: Text content
        type: string
      - description: "An array of content parts with a defined type, each can be of\
          \ type `text` or images can be passed with `image_url` or `image_file`.\
          \ Image types are only supported on [Vision-compatible models](/docs/models/overview)."
        items:
          $ref: "#/components/schemas/Array_of_content_parts_inner"
        minItems: 1
        title: Array of content parts
        type: array
      x-oaiExpandable: true
    MessageContentImageFileObject_image_file:
      properties:
        file_id:
          description: "The [File](/docs/api-reference/files) ID of the image in the\
            \ message content. Set `purpose=\"vision\"` when uploading the File if\
            \ you need to later display the file content."
          type: string
        detail:
          default: auto
          description: "Specifies the detail level of the image if specified by the\
            \ user. `low` uses fewer tokens, you can opt in to high resolution using\
            \ `high`."
          enum:
          - auto
          - low
          - high
          type: string
      required:
      - file_id
      type: object
    MessageDeltaContentImageFileObject_image_file:
      properties:
        file_id:
          description: "The [File](/docs/api-reference/files) ID of the image in the\
            \ message content. Set `purpose=\"vision\"` when uploading the File if\
            \ you need to later display the file content."
          type: string
        detail:
          default: auto
          description: "Specifies the detail level of the image if specified by the\
            \ user. `low` uses fewer tokens, you can opt in to high resolution using\
            \ `high`."
          enum:
          - auto
          - low
          - high
          type: string
      type: object
    MessageContentImageUrlObject_image_url:
      properties:
        url:
          description: "The external URL of the image, must be a supported image types:\
            \ jpeg, jpg, png, gif, webp."
          format: uri
          type: string
        detail:
          default: auto
          description: "Specifies the detail level of the image. `low` uses fewer\
            \ tokens, you can opt in to high resolution using `high`. Default value\
            \ is `auto`"
          enum:
          - auto
          - low
          - high
          type: string
      required:
      - url
      type: object
    MessageDeltaContentImageUrlObject_image_url:
      properties:
        url:
          description: "The URL of the image, must be a supported image types: jpeg,\
            \ jpg, png, gif, webp."
          type: string
        detail:
          default: auto
          description: "Specifies the detail level of the image. `low` uses fewer\
            \ tokens, you can opt in to high resolution using `high`."
          enum:
          - auto
          - low
          - high
          type: string
      type: object
    MessageContentTextObject_text_annotations_inner:
      oneOf:
      - $ref: "#/components/schemas/MessageContentTextAnnotationsFileCitationObject"
      - $ref: "#/components/schemas/MessageContentTextAnnotationsFilePathObject"
      x-oaiExpandable: true
    MessageContentTextObject_text:
      properties:
        value:
          description: The data that makes up the text.
          type: string
        annotations:
          items:
            $ref: "#/components/schemas/MessageContentTextObject_text_annotations_inner"
          type: array
      required:
      - annotations
      - value
      type: object
    MessageContentTextAnnotationsFileCitationObject_file_citation:
      properties:
        file_id:
          description: The ID of the specific File the citation is from.
          type: string
        quote:
          description: The specific quote in the file.
          type: string
      required:
      - file_id
      - quote
      type: object
    MessageContentTextAnnotationsFilePathObject_file_path:
      properties:
        file_id:
          description: The ID of the file that was generated.
          type: string
      required:
      - file_id
      type: object
    MessageDeltaContentTextObject_text_annotations_inner:
      oneOf:
      - $ref: "#/components/schemas/MessageDeltaContentTextAnnotationsFileCitationObject"
      - $ref: "#/components/schemas/MessageDeltaContentTextAnnotationsFilePathObject"
      x-oaiExpandable: true
    MessageDeltaContentTextObject_text:
      properties:
        value:
          description: The data that makes up the text.
          type: string
        annotations:
          items:
            $ref: "#/components/schemas/MessageDeltaContentTextObject_text_annotations_inner"
          type: array
      type: object
    MessageDeltaContentTextAnnotationsFileCitationObject_file_citation:
      properties:
        file_id:
          description: The ID of the specific File the citation is from.
          type: string
        quote:
          description: The specific quote in the file.
          type: string
      type: object
    MessageDeltaContentTextAnnotationsFilePathObject_file_path:
      properties:
        file_id:
          description: The ID of the file that was generated.
          type: string
      type: object
    RunStepObject_step_details:
      description: The details of the run step.
      oneOf:
      - $ref: "#/components/schemas/RunStepDetailsMessageCreationObject"
      - $ref: "#/components/schemas/RunStepDetailsToolCallsObject"
      type: object
      x-oaiExpandable: true
    RunStepObject_last_error:
      description: The last error associated with this run step. Will be `null` if
        there are no errors.
      nullable: true
      properties:
        code:
          description: One of `server_error` or `rate_limit_exceeded`.
          enum:
          - server_error
          - rate_limit_exceeded
          type: string
        message:
          description: A human-readable description of the error.
          type: string
      required:
      - code
      - message
      type: object
    RunStepDeltaObject_delta_step_details:
      description: The details of the run step.
      oneOf:
      - $ref: "#/components/schemas/RunStepDeltaStepDetailsMessageCreationObject"
      - $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsObject"
      type: object
      x-oaiExpandable: true
    RunStepDeltaObject_delta:
      description: The delta containing the fields that have changed on the run step.
      properties:
        step_details:
          $ref: "#/components/schemas/RunStepDeltaObject_delta_step_details"
      type: object
    RunStepDetailsMessageCreationObject_message_creation:
      properties:
        message_id:
          description: The ID of the message that was created by this run step.
          type: string
      required:
      - message_id
      type: object
    RunStepDeltaStepDetailsMessageCreationObject_message_creation:
      properties:
        message_id:
          description: The ID of the message that was created by this run step.
          type: string
      type: object
    RunStepDetailsToolCallsObject_tool_calls_inner:
      oneOf:
      - $ref: "#/components/schemas/RunStepDetailsToolCallsCodeObject"
      - $ref: "#/components/schemas/RunStepDetailsToolCallsFileSearchObject"
      - $ref: "#/components/schemas/RunStepDetailsToolCallsFunctionObject"
      x-oaiExpandable: true
    RunStepDeltaStepDetailsToolCallsObject_tool_calls_inner:
      oneOf:
      - $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeObject"
      - $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsFileSearchObject"
      - $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsFunctionObject"
      x-oaiExpandable: true
    RunStepDetailsToolCallsCodeObject_code_interpreter_outputs_inner:
      oneOf:
      - $ref: "#/components/schemas/RunStepDetailsToolCallsCodeOutputLogsObject"
      - $ref: "#/components/schemas/RunStepDetailsToolCallsCodeOutputImageObject"
      type: object
      x-oaiExpandable: true
    RunStepDetailsToolCallsCodeObject_code_interpreter:
      description: The Code Interpreter tool call definition.
      properties:
        input:
          description: The input to the Code Interpreter tool call.
          type: string
        outputs:
          description: "The outputs from the Code Interpreter tool call. Code Interpreter\
            \ can output one or more items, including text (`logs`) or images (`image`).\
            \ Each of these are represented by a different object type."
          items:
            $ref: "#/components/schemas/RunStepDetailsToolCallsCodeObject_code_interpreter_outputs_inner"
          type: array
      required:
      - input
      - outputs
      type: object
    RunStepDeltaStepDetailsToolCallsCodeObject_code_interpreter_outputs_inner:
      oneOf:
      - $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputLogsObject"
      - $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeOutputImageObject"
      type: object
      x-oaiExpandable: true
    RunStepDeltaStepDetailsToolCallsCodeObject_code_interpreter:
      description: The Code Interpreter tool call definition.
      properties:
        input:
          description: The input to the Code Interpreter tool call.
          type: string
        outputs:
          description: "The outputs from the Code Interpreter tool call. Code Interpreter\
            \ can output one or more items, including text (`logs`) or images (`image`).\
            \ Each of these are represented by a different object type."
          items:
            $ref: "#/components/schemas/RunStepDeltaStepDetailsToolCallsCodeObject_code_interpreter_outputs_inner"
          type: array
      type: object
    RunStepDetailsToolCallsCodeOutputImageObject_image:
      properties:
        file_id:
          description: "The [file](/docs/api-reference/files) ID of the image."
          type: string
      required:
      - file_id
      type: object
    RunStepDeltaStepDetailsToolCallsCodeOutputImageObject_image:
      properties:
        file_id:
          description: "The [file](/docs/api-reference/files) ID of the image."
          type: string
      type: object
    RunStepDetailsToolCallsFunctionObject_function:
      description: The definition of the function that was called.
      properties:
        name:
          description: The name of the function.
          type: string
        arguments:
          description: The arguments passed to the function.
          type: string
        output:
          description: "The output of the function. This will be `null` if the outputs\
            \ have not been [submitted](/docs/api-reference/runs/submitToolOutputs)\
            \ yet."
          nullable: true
          type: string
      required:
      - arguments
      - name
      - output
      type: object
    RunStepDeltaStepDetailsToolCallsFunctionObject_function:
      description: The definition of the function that was called.
      properties:
        name:
          description: The name of the function.
          type: string
        arguments:
          description: The arguments passed to the function.
          type: string
        output:
          description: "The output of the function. This will be `null` if the outputs\
            \ have not been [submitted](/docs/api-reference/runs/submitToolOutputs)\
            \ yet."
          nullable: true
          type: string
      type: object
    VectorStoreObject_file_counts:
      properties:
        in_progress:
          description: The number of files that are currently being processed.
          type: integer
        completed:
          description: The number of files that have been successfully processed.
          type: integer
        failed:
          description: The number of files that have failed to process.
          type: integer
        cancelled:
          description: The number of files that were cancelled.
          type: integer
        total:
          description: The total number of files.
          type: integer
      required:
      - cancelled
      - completed
      - failed
      - in_progress
      - total
      type: object
    VectorStoreFileObject_last_error:
      description: The last error associated with this vector store file. Will be
        `null` if there are no errors.
      nullable: true
      properties:
        code:
          description: One of `server_error` or `rate_limit_exceeded`.
          enum:
          - internal_error
          - file_not_found
          - parsing_error
          - unhandled_mime_type
          type: string
        message:
          description: A human-readable description of the error.
          type: string
      required:
      - code
      - message
      type: object
    VectorStoreFileBatchObject_file_counts:
      properties:
        in_progress:
          description: The number of files that are currently being processed.
          type: integer
        completed:
          description: The number of files that have been processed.
          type: integer
        failed:
          description: The number of files that have failed to process.
          type: integer
        cancelled:
          description: The number of files that where cancelled.
          type: integer
        total:
          description: The total number of files.
          type: integer
      required:
      - cancelled
      - completed
      - failed
      - in_progress
      - total
      type: object
    ThreadStreamEvent_oneOf:
      description: "Occurs when a new [thread](/docs/api-reference/threads/object)\
        \ is created."
      properties:
        event:
          enum:
          - thread.created
          type: string
        data:
          $ref: "#/components/schemas/ThreadObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [thread](/docs/api-reference/threads/object)"
    RunStreamEvent_oneOf:
      description: "Occurs when a new [run](/docs/api-reference/runs/object) is created."
      properties:
        event:
          enum:
          - thread.run.created
          type: string
        data:
          $ref: "#/components/schemas/RunObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_1:
      description: "Occurs when a [run](/docs/api-reference/runs/object) moves to\
        \ a `queued` status."
      properties:
        event:
          enum:
          - thread.run.queued
          type: string
        data:
          $ref: "#/components/schemas/RunObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_2:
      description: "Occurs when a [run](/docs/api-reference/runs/object) moves to\
        \ an `in_progress` status."
      properties:
        event:
          enum:
          - thread.run.in_progress
          type: string
        data:
          $ref: "#/components/schemas/RunObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_3:
      description: "Occurs when a [run](/docs/api-reference/runs/object) moves to\
        \ a `requires_action` status."
      properties:
        event:
          enum:
          - thread.run.requires_action
          type: string
        data:
          $ref: "#/components/schemas/RunObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_4:
      description: "Occurs when a [run](/docs/api-reference/runs/object) is completed."
      properties:
        event:
          enum:
          - thread.run.completed
          type: string
        data:
          $ref: "#/components/schemas/RunObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_5:
      description: "Occurs when a [run](/docs/api-reference/runs/object) ends with\
        \ status `incomplete`."
      properties:
        event:
          enum:
          - thread.run.incomplete
          type: string
        data:
          $ref: "#/components/schemas/RunObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_6:
      description: "Occurs when a [run](/docs/api-reference/runs/object) fails."
      properties:
        event:
          enum:
          - thread.run.failed
          type: string
        data:
          $ref: "#/components/schemas/RunObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_7:
      description: "Occurs when a [run](/docs/api-reference/runs/object) moves to\
        \ a `cancelling` status."
      properties:
        event:
          enum:
          - thread.run.cancelling
          type: string
        data:
          $ref: "#/components/schemas/RunObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_8:
      description: "Occurs when a [run](/docs/api-reference/runs/object) is cancelled."
      properties:
        event:
          enum:
          - thread.run.cancelled
          type: string
        data:
          $ref: "#/components/schemas/RunObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStreamEvent_oneOf_9:
      description: "Occurs when a [run](/docs/api-reference/runs/object) expires."
      properties:
        event:
          enum:
          - thread.run.expired
          type: string
        data:
          $ref: "#/components/schemas/RunObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run](/docs/api-reference/runs/object)"
    RunStepStreamEvent_oneOf:
      description: "Occurs when a [run step](/docs/api-reference/runs/step-object)\
        \ is created."
      properties:
        event:
          enum:
          - thread.run.step.created
          type: string
        data:
          $ref: "#/components/schemas/RunStepObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/runs/step-object)"
    RunStepStreamEvent_oneOf_1:
      description: "Occurs when a [run step](/docs/api-reference/runs/step-object)\
        \ moves to an `in_progress` state."
      properties:
        event:
          enum:
          - thread.run.step.in_progress
          type: string
        data:
          $ref: "#/components/schemas/RunStepObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/runs/step-object)"
    RunStepStreamEvent_oneOf_2:
      description: "Occurs when parts of a [run step](/docs/api-reference/runs/step-object)\
        \ are being streamed."
      properties:
        event:
          enum:
          - thread.run.step.delta
          type: string
        data:
          $ref: "#/components/schemas/RunStepDeltaObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run step delta](/docs/api-reference/assistants-streaming/run-step-delta-object)"
    RunStepStreamEvent_oneOf_3:
      description: "Occurs when a [run step](/docs/api-reference/runs/step-object)\
        \ is completed."
      properties:
        event:
          enum:
          - thread.run.step.completed
          type: string
        data:
          $ref: "#/components/schemas/RunStepObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/runs/step-object)"
    RunStepStreamEvent_oneOf_4:
      description: "Occurs when a [run step](/docs/api-reference/runs/step-object)\
        \ fails."
      properties:
        event:
          enum:
          - thread.run.step.failed
          type: string
        data:
          $ref: "#/components/schemas/RunStepObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/runs/step-object)"
    RunStepStreamEvent_oneOf_5:
      description: "Occurs when a [run step](/docs/api-reference/runs/step-object)\
        \ is cancelled."
      properties:
        event:
          enum:
          - thread.run.step.cancelled
          type: string
        data:
          $ref: "#/components/schemas/RunStepObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/runs/step-object)"
    RunStepStreamEvent_oneOf_6:
      description: "Occurs when a [run step](/docs/api-reference/runs/step-object)\
        \ expires."
      properties:
        event:
          enum:
          - thread.run.step.expired
          type: string
        data:
          $ref: "#/components/schemas/RunStepObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [run step](/docs/api-reference/runs/step-object)"
    MessageStreamEvent_oneOf:
      description: "Occurs when a [message](/docs/api-reference/messages/object) is\
        \ created."
      properties:
        event:
          enum:
          - thread.message.created
          type: string
        data:
          $ref: "#/components/schemas/MessageObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [message](/docs/api-reference/messages/object)"
    MessageStreamEvent_oneOf_1:
      description: "Occurs when a [message](/docs/api-reference/messages/object) moves\
        \ to an `in_progress` state."
      properties:
        event:
          enum:
          - thread.message.in_progress
          type: string
        data:
          $ref: "#/components/schemas/MessageObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [message](/docs/api-reference/messages/object)"
    MessageStreamEvent_oneOf_2:
      description: "Occurs when parts of a [Message](/docs/api-reference/messages/object)\
        \ are being streamed."
      properties:
        event:
          enum:
          - thread.message.delta
          type: string
        data:
          $ref: "#/components/schemas/MessageDeltaObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [message delta](/docs/api-reference/assistants-streaming/message-delta-object)"
    MessageStreamEvent_oneOf_3:
      description: "Occurs when a [message](/docs/api-reference/messages/object) is\
        \ completed."
      properties:
        event:
          enum:
          - thread.message.completed
          type: string
        data:
          $ref: "#/components/schemas/MessageObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [message](/docs/api-reference/messages/object)"
    MessageStreamEvent_oneOf_4:
      description: "Occurs when a [message](/docs/api-reference/messages/object) ends\
        \ before it is completed."
      properties:
        event:
          enum:
          - thread.message.incomplete
          type: string
        data:
          $ref: "#/components/schemas/MessageObject"
      required:
      - data
      - event
      type: object
      x-oaiMeta:
        dataDescription: "`data` is a [message](/docs/api-reference/messages/object)"
    Batch_errors_data_inner:
      properties:
        code:
          description: An error code identifying the error type.
          type: string
        message:
          description: A human-readable message providing more details about the error.
          type: string
        param:
          description: "The name of the parameter that caused the error, if applicable."
          nullable: true
          type: string
        line:
          description: "The line number of the input file where the error occurred,\
            \ if applicable."
          nullable: true
          type: integer
      type: object
    Batch_errors:
      properties:
        object:
          description: "The object type, which is always `list`."
          type: string
        data:
          items:
            $ref: "#/components/schemas/Batch_errors_data_inner"
          type: array
      type: object
    Batch_request_counts:
      description: The request counts for different statuses within the batch.
      properties:
        total:
          description: Total number of requests in the batch.
          type: integer
        completed:
          description: Number of requests that have been completed successfully.
          type: integer
        failed:
          description: Number of requests that have failed.
          type: integer
      required:
      - completed
      - failed
      - total
      type: object
    BatchRequestOutput_response:
      nullable: true
      properties:
        status_code:
          description: The HTTP status code of the response
          type: integer
        request_id:
          description: An unique identifier for the OpenAI API request. Please include
            this request ID when contacting support.
          type: string
        body:
          description: The JSON body of the response
          type: object
          x-oaiTypeLabel: map
      type: object
    BatchRequestOutput_error:
      description: "For requests that failed with a non-HTTP error, this will contain\
        \ more information on the cause of the failure."
      nullable: true
      properties:
        code:
          description: A machine-readable error code.
          type: string
        message:
          description: A human-readable error message.
          type: string
      type: object
  securitySchemes:
    ApiKeyAuth:
      scheme: bearer
      type: http
x-oaiMeta:
  navigationGroups:
  - id: endpoints
    title: Endpoints
  - id: assistants
    title: Assistants
  - id: legacy
    title: Legacy
  groups:
  - id: chat
    title: Chat
    description: |
      Given a list of messages comprising a conversation, the model will return a response.

      Related guide: [Chat Completions](/docs/guides/text-generation)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createChatCompletion
      path: create
    - type: object
      key: CreateChatCompletionResponse
      path: object
    - type: object
      key: CreateChatCompletionStreamResponse
      path: streaming
  - id: embeddings
    title: Embeddings
    description: |
      Get a vector representation of a given input that can be easily consumed by machine learning models and algorithms.

      Related guide: [Embeddings](/docs/guides/embeddings)
    navigationGroup: endpoints
    sections:
    - type: endpoint
      key: createEmbedding
      path: create
    - type: object
      key: Embedding
      path: object

